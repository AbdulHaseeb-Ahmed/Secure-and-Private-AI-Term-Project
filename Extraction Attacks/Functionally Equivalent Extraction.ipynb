{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Functionally Equivalent Extraction.ipynb","provenance":[],"authorship_tag":"ABX9TyMNhC7ylO+mBXqoZmGQMPN6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"h81j3blvP7cd","colab_type":"code","outputId":"3bf10977-e5f5-4c1d-e1e0-1b9e7623eff7","executionInfo":{"status":"ok","timestamp":1588021847413,"user_tz":240,"elapsed":16122,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":969}},"source":["%tensorflow_version 1.x\n","!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans/\n","!pip install adversarial-robustness-toolbox"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Cloning into 'cleverhans'...\n","remote: Enumerating objects: 13501, done.\u001b[K\n","remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n","Receiving objects: 100% (13501/13501), 8.40 MiB | 24.73 MiB/s, done.\n","Resolving deltas: 100% (9494/9494), done.\n","Processing ./cleverhans\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 2.9MB/s \n","\u001b[?25hCollecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n","Collecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n","Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n","Building wheels for collected packages: cleverhans\n","  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=6637460de83afed549a1ae82f4b4519eeb453a1d191e75a55b35a365bf958b8d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_1e1wf41/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n","Successfully built cleverhans\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 41.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0wEHZsP6QdiT","colab_type":"code","outputId":"38416a99-49d4-4c7f-a252-83f9b466c9df","executionInfo":{"status":"error","timestamp":1588031420086,"user_tz":240,"elapsed":4656,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["  \n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","from art.attacks import FunctionallyEquivalentExtraction\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","img_rows = 32\n","img_cols = 32\n","number_channels = 3\n","\n","# Step 1: Load the CIFAR 10 dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","\n","input_shape = (number_channels * img_rows * img_cols,)\n","print(input_shape)\n","\n","x_train = x_train.reshape((x_train.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","x_test = x_test.reshape((x_test.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","\n","mean = np.mean(x_train)\n","std = np.std(x_train)\n","\n","x_train = (x_train - mean) / std\n","x_test = (x_test - mean) / std\n","\n","y_train = tf.keras.utils.to_categorical(y_train, number_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, number_classes)\n","\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","\n","\n","# Step 2: Load the victim model\n","hub_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"\n","embed = hub.KerasLayer(hub_url, input_shape=(32,32,3) )\n","model = tf.keras.Sequential([\n","    embed,\n","    tf.keras.layers.Activation( 'softmax' )\n","])\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","model.summary()\n","victim_classifier = KerasClassifier(model=model, use_logits=True, clip_values=(0., 1.))\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = victim_classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"],"execution_count":37,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","x_train size: 153600000\n","y_train shape: (50000, 10)\n","y_train size: 500000\n","x_test shape: (10000, 32, 32, 3)\n","x_test size: 30720000\n","y_test shape: (10000, 10)\n","y_test size: 100000\n","\n","(3072,)\n","x_train shape: (50000, 3072)\n","x_train size: 153600000\n","y_train shape: (50000, 10, 10)\n","y_train size: 5000000\n","x_test shape: (10000, 3072)\n","x_test size: 30720000\n","y_test shape: (10000, 10, 10)\n","y_test size: 1000000\n","\n","WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0db3bbbc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0db3bbbc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f0db3bbbc50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer_5 (KerasLayer)   (None, 10)                7796426   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 7,796,426\n","Trainable params: 0\n","Non-trainable params: 7,796,426\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-04412137d927>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Step 3: Evaluate the victim model on the benign dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvictim_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# giving the classifier the x_test of the CIFAR-10 dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0maccuracy_benign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculates the accuracy of the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy on benign test examples for victim classifier: {}%\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_benign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/classifiers/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/classifiers/keras.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Apply postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    561\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected keras_layer_5_input to have 4 dimensions, but got array with shape (128, 3072)"]}]},{"cell_type":"code","metadata":{"id":"w64lzfOtAQly","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"f3d2ae7e-8b8e-4738-da8c-c9878d0dd8ae","executionInfo":{"status":"ok","timestamp":1588030715563,"user_tz":240,"elapsed":2496,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["img_rows = 32\n","img_cols = 32\n","number_channels = 3\n","\n","input_shape = (number_channels * img_rows * img_cols,)\n","print(input_shape)\n","\n","x_train = x_train.reshape((x_train.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","x_test = x_test.reshape((x_test.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","\n","mean = np.mean(x_train)\n","std = np.std(x_train)\n","\n","x_train = (x_train - mean) / std\n","x_test = (x_test - mean) / std\n","\n","y_train = tf.keras.utils.to_categorical(y_train, number_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, number_classes)\n","\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n"],"execution_count":28,"outputs":[{"output_type":"stream","text":["(3072,)\n","x_train shape: (50000, 3072)\n","x_train size: 153600000\n","y_train shape: (50000, 10, 10)\n","y_train size: 5000000\n","x_test shape: (10000, 3072)\n","x_test size: 30720000\n","y_test shape: (10000, 10, 10)\n","y_test size: 1000000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"669XRzz-QtEI","colab_type":"code","outputId":"49afdfa6-0450-4d12-efe9-e86658298e88","executionInfo":{"status":"error","timestamp":1588030618026,"user_tz":240,"elapsed":348,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":375}},"source":["print(x_train[0:100].shape)\n","\n","extraction_attack = FunctionallyEquivalentExtraction(classifier=victim_classifier, num_neurons=3072) \n","stolen_classifier = extraction_attack.extract(x_train[0:100])\n","#stolen_classifier = extraction_attack._o_l(x=x_train)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["(100, 32, 32, 3)\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-6122fc656373>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mextraction_attack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionallyEquivalentExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvictim_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mstolen_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraction_attack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#stolen_classifier = extraction_attack._o_l(x=x_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/attack.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, x, y, delta_0, fraction_true, rel_diff_slope, rel_diff_value, delta_init_value, delta_value_max, d2_min, d_step, delta_sign, unit_vector_scale, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[1;32m    124\u001b[0m         self._critical_point_search(\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mdelta_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelta_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfraction_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfraction_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_diff_slope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_diff_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_diff_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_diff_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         )\n\u001b[1;32m    127\u001b[0m         self._weight_recovery(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py\u001b[0m in \u001b[0;36m_critical_point_search\u001b[0;34m(self, delta_0, fraction_true, rel_diff_slope, rel_diff_value)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mx_2_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0mm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_o_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1_p\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_o_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0mm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_o_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_o_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2_m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py\u001b[0m in \u001b[0;36m_o_l\u001b[0;34m(self, x, e_j)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me_j\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0me_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUMPY_DTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/classifiers/classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/art/classifiers/keras.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Apply postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_or_infer_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[0;32m--> 716\u001b[0;31m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[1;32m    717\u001b[0m     return predict_loop(\n\u001b[1;32m    718\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2469\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2471\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2473\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    561\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected keras_layer_1_input to have 4 dimensions, but got array with shape (1, 3072)"]}]},{"cell_type":"code","metadata":{"id":"w700CZre-cPx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"f9999cfd-066d-4fa8-fecd-d04e234355ab","executionInfo":{"status":"ok","timestamp":1588031435866,"user_tz":240,"elapsed":661,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["import tensorflow as tf\n","\n","tf.compat.v1.disable_eager_execution()\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","np.random.seed(0)\n","\n","number_neurons = 16\n","\n","batch_size = 128\n","number_classes = 10\n","epochs = 10\n","img_rows = 28\n","img_cols = 28\n","number_channels = 1\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")"],"execution_count":38,"outputs":[{"output_type":"stream","text":["x_train shape: (60000, 28, 28)\n","x_train size: 47040000\n","y_train shape: (60000,)\n","y_train size: 60000\n","x_test shape: (10000, 28, 28)\n","x_test size: 7840000\n","y_test shape: (10000,)\n","y_test size: 10000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g4AQKhNa-omo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"outputId":"6e9192f2-36d5-418f-e43e-aaa076410ade","executionInfo":{"status":"ok","timestamp":1588031436993,"user_tz":240,"elapsed":311,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, number_channels)\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, number_channels)\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")"],"execution_count":39,"outputs":[{"output_type":"stream","text":["x_train shape: (60000, 28, 28, 1)\n","x_train size: 47040000\n","y_train shape: (60000,)\n","y_train size: 60000\n","x_test shape: (10000, 28, 28, 1)\n","x_test size: 7840000\n","y_test shape: (10000,)\n","y_test size: 10000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f5tQM3eu-zLz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"f5531efa-f40d-4825-b002-c1bb192568d2","executionInfo":{"status":"ok","timestamp":1588031439251,"user_tz":240,"elapsed":547,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["input_shape = (number_channels * img_rows * img_cols,)\n","print(input_shape)\n","\n","x_train = x_train.reshape((x_train.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","x_test = x_test.reshape((x_test.shape[0], number_channels * img_rows * img_cols)).astype(\"float64\")\n","\n","mean = np.mean(x_train)\n","std = np.std(x_train)\n","\n","x_train = (x_train - mean) / std\n","x_test = (x_test - mean) / std\n","\n","y_train = tf.keras.utils.to_categorical(y_train, number_classes)\n","y_test = tf.keras.utils.to_categorical(y_test, number_classes)\n","\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["(784,)\n","x_train shape: (60000, 784)\n","x_train size: 47040000\n","y_train shape: (60000, 10)\n","y_train size: 600000\n","x_test shape: (10000, 784)\n","x_test size: 7840000\n","y_test shape: (10000, 10)\n","y_test size: 100000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PuBGogUf-97L","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":408},"outputId":"b882d399-b625-4024-8704-24034186e519","executionInfo":{"status":"ok","timestamp":1588031457325,"user_tz":240,"elapsed":16677,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["model = Sequential()\n","model.add(Dense(number_neurons, activation=\"relu\", input_shape=input_shape))\n","model.add(Dense(number_classes, activation=\"linear\"))\n","\n","model.compile(\n","    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001,),\n","    metrics=[\"accuracy\"],\n",")\n","print(x_train.shape)\n","print(y_train.shape)\n","model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n","\n","model.save(\"./model.h5\")\n","\n","score_target = model.evaluate(x_test, y_test, verbose=0)\n","\n","target_classifier = KerasClassifier(model=model, use_logits=True, clip_values=(0, 1))\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["(60000, 784)\n","(60000, 10)\n","Train on 60000 samples, validate on 10000 samples\n","Epoch 1/10\n","60000/60000 [==============================] - 2s 29us/sample - loss: 1.5431 - acc: 0.5148 - val_loss: 0.9395 - val_acc: 0.7228\n","Epoch 2/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.7034 - acc: 0.8022 - val_loss: 0.5126 - val_acc: 0.8595\n","Epoch 3/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.4692 - acc: 0.8690 - val_loss: 0.3961 - val_acc: 0.8902\n","Epoch 4/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.3860 - acc: 0.8903 - val_loss: 0.3439 - val_acc: 0.9054\n","Epoch 5/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.3419 - acc: 0.9028 - val_loss: 0.3128 - val_acc: 0.9132\n","Epoch 6/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.3137 - acc: 0.9108 - val_loss: 0.2926 - val_acc: 0.9174\n","Epoch 7/10\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.2933 - acc: 0.9170 - val_loss: 0.2772 - val_acc: 0.9227\n","Epoch 8/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.2776 - acc: 0.9219 - val_loss: 0.2646 - val_acc: 0.9273\n","Epoch 9/10\n","60000/60000 [==============================] - 1s 23us/sample - loss: 0.2647 - acc: 0.9255 - val_loss: 0.2542 - val_acc: 0.9290\n","Epoch 10/10\n","60000/60000 [==============================] - 1s 22us/sample - loss: 0.2540 - acc: 0.9287 - val_loss: 0.2461 - val_acc: 0.9306\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ge-bKLw3_IH6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"3b2a31f2-326b-4608-9f30-99ddce881d43"},"source":["print(x_test.shape)\n","print(number_neurons)\n","fee = FunctionallyEquivalentExtraction(classifier=target_classifier, num_neurons=number_neurons)\n","bbc = fee.extract(x_test[0:100])\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(10000, 784)\n","16\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:232: RuntimeWarning: divide by zero encountered in true_divide\n","  t_hat = t_1 + np.divide(y_2 - y_1 - (t_2 - t_1) * m_2, m_1 - m_2)\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:233: RuntimeWarning: divide by zero encountered in true_divide\n","  y_hat = y_1 + m_1 * np.divide(y_2 - y_1 - (t_2 - t_1) * m_2, m_1 - m_2)\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:247: RuntimeWarning: invalid value encountered in less\n","  np.sum(np.abs((y_hat - y) / y) < rel_diff_value) > fraction_true * self.num_classes\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:228: RuntimeWarning: divide by zero encountered in true_divide\n","  if np.sum(np.abs((m_1 - m_2) / m_1) < rel_diff_slope) > fraction_true * self.num_classes:\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:249: RuntimeWarning: divide by zero encountered in true_divide\n","  and np.sum(np.abs((m_x_1 - m_x_2) / m_x_1) > rel_diff_slope) > fraction_true * self.num_classes\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:228: RuntimeWarning: invalid value encountered in true_divide\n","  if np.sum(np.abs((m_1 - m_2) / m_1) < rel_diff_slope) > fraction_true * self.num_classes:\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:228: RuntimeWarning: invalid value encountered in less\n","  if np.sum(np.abs((m_1 - m_2) / m_1) < rel_diff_slope) > fraction_true * self.num_classes:\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:233: RuntimeWarning: invalid value encountered in multiply\n","  y_hat = y_1 + m_1 * np.divide(y_2 - y_1 - (t_2 - t_1) * m_2, m_1 - m_2)\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:249: RuntimeWarning: invalid value encountered in true_divide\n","  and np.sum(np.abs((m_x_1 - m_x_2) / m_x_1) > rel_diff_slope) > fraction_true * self.num_classes\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:249: RuntimeWarning: invalid value encountered in greater\n","  and np.sum(np.abs((m_x_1 - m_x_2) / m_x_1) > rel_diff_slope) > fraction_true * self.num_classes\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:232: RuntimeWarning: invalid value encountered in true_divide\n","  t_hat = t_1 + np.divide(y_2 - y_1 - (t_2 - t_1) * m_2, m_1 - m_2)\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:233: RuntimeWarning: invalid value encountered in true_divide\n","  y_hat = y_1 + m_1 * np.divide(y_2 - y_1 - (t_2 - t_1) * m_2, m_1 - m_2)\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:222: RuntimeWarning: invalid value encountered in true_divide\n","  m_1 = (self._o_l(x_1_p) - self._o_l(x_1)) / epsilon\n","/usr/local/lib/python3.6/dist-packages/art/attacks/extraction/functionally_equivalent_extraction.py:223: RuntimeWarning: invalid value encountered in true_divide\n","  m_2 = (self._o_l(x_2) - self._o_l(x_2_m)) / epsilon\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"aJu2ScvU_O_I","colab_type":"code","colab":{}},"source":["y_test_predicted_extracted = bbc.predict(x_test)\n","y_test_predicted_target = target_classifier.predict(x_test)\n","\n","print(\"Target model - Test accuracy:\", score_target[1])\n","print(\n","    \"Extracted model - Test accuracy:\",\n","    np.sum(np.argmax(y_test_predicted_extracted, axis=1) == np.argmax(y_test, axis=1)) / y_test.shape[0],\n",")\n","print(\n","    \"Extracted model - Test Fidelity:\",\n","    np.sum(np.argmax(y_test_predicted_extracted, axis=1) == np.argmax(y_test_predicted_target, axis=1))\n","    / y_test_predicted_target.shape[0],\n",")"],"execution_count":0,"outputs":[]}]}
