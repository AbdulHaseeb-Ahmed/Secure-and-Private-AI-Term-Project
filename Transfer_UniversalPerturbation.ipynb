{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer_UniversalPerturbation.ipynb","provenance":[{"file_id":"https://github.com/podschwadt/teaching/blob/master/defend_cnn.ipynb","timestamp":1582598056181}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IP3q_4zswrk0","colab_type":"code","outputId":"81c22c47-c9ef-4846-dd00-6cd9bb88cffd","executionInfo":{"status":"ok","timestamp":1588374747645,"user_tz":240,"elapsed":30623,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vsvgCPv17t3u","colab_type":"code","outputId":"5473394c-d5ac-46df-d84b-1c1b0fffefcb","executionInfo":{"status":"ok","timestamp":1588374762991,"user_tz":240,"elapsed":13603,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["%tensorflow_version 1.x\n","!pip install adversarial-robustness-toolbox\n","#!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 9.7MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 27.5MB/s \n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n","Collecting cleverhans\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 9.5MB/s \n","\u001b[?25hCollecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 28.3MB/s \n","\u001b[?25hCollecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans) (0.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.3)\n","Collecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n","Installing collected packages: nose, mnist, pycodestyle, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CT3K5k-fIIZ0","colab_type":"code","outputId":"deaba2f5-b822-4348-a670-eb9aee3d9d95","executionInfo":{"status":"ok","timestamp":1588374805796,"user_tz":240,"elapsed":37109,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":513}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import UniversalPerturbation\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR 10 dataset\n","(x_train_victim, y_train_victim), (x_test_victim, y_test_victim), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train_victim shape: \" + str(x_train_victim.shape) + \"\\n\" + \"x_train_victim size: \" + str(x_train_victim.size) + \"\\n\" +\n","      \"y_train_victim shape: \" + str(y_train_victim.shape) + \"\\n\" + \"y_train_victim size: \" + str(y_train_victim.size) + \"\\n\" +\n","      \"x_test_victim shape: \" + str(x_test_victim.shape) + \"\\n\" + \"x_test_victim size: \" + str(x_test_victim.size) + \"\\n\" +\n","      \"y_test_victim shape: \" + str(y_test_victim.shape) + \"\\n\" + \"y_test_victim size: \" + str(y_test_victim.size) + \"\\n\")\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"  # @param {type:\"string\"}\n","IMAGE_SHAPE = (32, 32)\n","victim_classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE + (3,))]), clip_values=(min_, max_))\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = victim_classifier.predict(x_test_victim)\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_victim, axis=1)) / len(y_test_victim)\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["x_train_victim shape: (50000, 32, 32, 3)\n","x_train_victim size: 153600000\n","y_train_victim shape: (50000, 10)\n","y_train_victim size: 500000\n","x_test_victim shape: (10000, 32, 32, 3)\n","x_test_victim size: 30720000\n","y_test_victim shape: (10000, 10)\n","y_test_victim size: 100000\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f6edec7e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f6edec7e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f6edec7e908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on benign test examples: 94.52000000000001%\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vI5-e-Tdxp2-","colab_type":"code","outputId":"64ab3811-b5b0-46ce-c76c-4eae046d2010","executionInfo":{"status":"ok","timestamp":1588374809848,"user_tz":240,"elapsed":37817,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["X_train_substitute = np.load('/content/gdrive/My Drive/X_synthetic.npy') \n","Y_train_substitute = np.load('/content/gdrive/My Drive/Y_synthetic.npy') \n","print(\"X_train_substitute shape: \" + str(X_train_substitute.shape) + \"\\n\" + \"X_train_substitute size: \" + str(X_train_substitute.size) + \"\\n\" + \n","      \"Y_train_substitute shape: \" + str(Y_train_substitute.shape) + \"\\n\" + \"Y_train_substitute size: \" + str(Y_train_substitute.size) + \"\\n\")\n","print()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["X_train_substitute shape: (15000, 32, 32, 3)\n","X_train_substitute size: 46080000\n","Y_train_substitute shape: (15000, 10)\n","Y_train_substitute size: 150000\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KXwKhZGd1_0P","colab_type":"code","outputId":"c850dddf-2ca6-494c-88ee-3821fd9fa9a2","executionInfo":{"status":"ok","timestamp":1588374810052,"user_tz":240,"elapsed":36446,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# Step 2: Create the model\n","model_substitute = Sequential()\n","model_substitute.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=X_train_substitute.shape[1:]))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Conv2D(32, (3, 3)))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n","model_substitute.add(Dropout(0.25))\n","\n","model_substitute.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Conv2D(64, (3, 3)))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n","model_substitute.add(Dropout(0.25))\n","\n","model_substitute.add(Flatten())\n","model_substitute.add(Dense(512))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Dropout(0.5))\n","model_substitute.add(Dense(10))\n","model_substitute.add(Activation(\"softmax\"))\n","\n","model_substitute.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","\n","\n","# Step 3: Create the classifier\n","substitute_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"7jd7KQre0Q4o","colab_type":"code","outputId":"e7c27b6d-8e9c-49a4-8e99-3c576dad6ba2","executionInfo":{"status":"ok","timestamp":1588374813810,"user_tz":240,"elapsed":3742,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Step 1: Load the subset data\n","X = np.load('/content/gdrive/My Drive/X_subset.npy') \n","Y = np.load('/content/gdrive/My Drive/Y_subset.npy') \n","print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n","      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n","print()\n","\n","X_test_substitute = X[7500:]\n","Y_test_substitute = Y[7500:]\n","print(\"X_test_substitute shape: \" + str(X_test_substitute.shape) + \"\\n\" + \"X_test_substitute size: \" + str(X_test_substitute.size) + \"\\n\" + \n","      \"Y_test_substitute shape: \" + str(Y_test_substitute.shape) + \"\\n\" + \"Y_test_substitute size: \" + str(Y_test_substitute.size) + \"\\n\")\n","print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["X shape: (10000, 32, 32, 3)\n","X size: 30720000\n","Y shape: (10000, 10)\n","Y size: 100000\n","\n","\n","X_test_substitute shape: (2500, 32, 32, 3)\n","X_test_substitute size: 7680000\n","Y_test_substitute shape: (2500, 10)\n","Y_test_substitute size: 25000\n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-Zp1LWyZ1WMM","colab_type":"code","outputId":"f325b24e-6ae5-4996-e186-ec8c01920305","executionInfo":{"status":"ok","timestamp":1588374814844,"user_tz":240,"elapsed":4769,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#Step 4: Evaluate the ART classifier on benign test examples\n","predictions = substitute_classifier.predict(X_test_substitute)\n","accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(Y_test_substitute, axis=1)) / len(Y_test_substitute)\n","print(\"Accuracy on benign test examples for substitute classifier: {}%\".format(accuracy * 100))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Accuracy on benign test examples for substitute classifier: 10.0%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GdKCtwP8041l","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zR5y5wotw_X3","colab_type":"code","outputId":"a7efcc2c-d357-44fc-d79f-c04c1c3d15a8","executionInfo":{"status":"ok","timestamp":1588375022973,"user_tz":240,"elapsed":107332,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1E1Ztw-7KmTQyDk6xTJ_uik9B0ZRzjZYn"}},"source":["# Step 4 and 5\n","def getaccuracy_forone_extraction(x_test, y_test):\n","    # Step 4: Collect 10 instances of each case from test examples\n","    def exract_ten_classes( data, labels, classes=(0,1,2,3,4,5,6,7,8,9), no_instance=10 ):\n","        x_pre = [] # list to collect the x_test set\n","        y_pre = [] # list to collect the y_test set\n","        for class_label in range(0, 10): # loop through each of the classes\n","            index = random.randint(0, 1250) # randomly choose an index from the x_test, as means of getting different instances from each class\n","            iteration = no_instance # number of instance of each class to collect\n","            while (iteration != 0):\n","                if np.argmax(labels[index]) == classes[class_label]: # check if the current index label matches the specified class label we are looking for\n","                    x_pre.append(data[index]) # add the image to the x_test set\n","                    y_pre.append(int(class_label)) # add the image label to the y_test set\n","                    iteration = iteration - 1 # reduce # of instances by 1\n","                index = index + 1 # go to next index till next label is of the current class\n","        x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","        y = keras.utils.to_categorical( np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","        return x, y\n","\n","    x_test_adv_pre, y_test_adv = exract_ten_classes( X_test_substitute, Y_test_substitute ) # call method to get 10 instances of each class\n","    #print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","     #     \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","    # Step 5: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","    attack_eps_5 = UniversalPerturbation(classifier=substitute_classifier, attacker=\"fgsm\", delta = 0.05) # generate attack with FGSM method with eps = 0.05\n","    x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_5 = victim_classifier.predict(x_test_adv_eps_5) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","    attack_eps_10 = UniversalPerturbation(classifier=substitute_classifier, attacker=\"fgsm\", delta = 0.1) # generate attack with FGSM method with eps = 0.1\n","    x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_10 = victim_classifier.predict(x_test_adv_eps_10) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","    attack_eps_50 = UniversalPerturbation(classifier=substitute_classifier, attacker=\"fgsm\", delta = 0.5) # generate attack with FGSM method with eps = 0.5\n","    x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_50 = victim_classifier.predict(x_test_adv_eps_50) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","    attack_eps_95 = UniversalPerturbation(classifier=substitute_classifier, attacker=\"fgsm\", delta = 0.95) # generate attack with FGSM method with eps = 0.95\n","    x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_95 = victim_classifier.predict(x_test_adv_eps_95) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","    accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100] # create a list which holds the accuracy of the classifier with differnt values of epsilon for the FGSM attack\n","\n","    all_count = [] # used to hold the accuracy of each attack on each label, i.e. original, eps = 5, eps 10, eps = 50, eps = 95\n","    for j in range(0, 100, 10): # iterate through each class\n","        count = [0, 0, 0, 0, 0] # used to hold accuracy of each attack for this instance of the label\n","        for i in range(j, j + 10): # loop through each instance of the current class\n","            sample_pre = x_test_adv_pre[i, :] # load the current image from the x set\n","            label_pre = np.argmax(victim_classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2])))) # predict the label of the original image from x set\n","            sample_post_eps_5 = x_test_adv_eps_5[i, :]\n","            label_post_eps_5 = np.argmax(victim_classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","            sample_post_eps_10 = x_test_adv_eps_10[i, :]\n","            label_post_eps_10 = np.argmax(victim_classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","            sample_post_eps_50 = x_test_adv_eps_50[i, :]\n","            label_post_eps_50 = np.argmax(victim_classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","            sample_post_eps_95 = x_test_adv_eps_95[i, :]\n","            label_post_eps_95 = np.argmax(victim_classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","            if (label_pre == np.argmax(y_test_adv[i])): # if's are to update the count list to tally correct predictions\n","                count[0] = count[0] + 1\n","            if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","                count[1] = count[1] + 1\n","            if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","                count[2] = count[2] + 1\n","            if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","                count[3] = count[3] + 1\n","            if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","                count[4] = count[4] + 1\n","        all_count.append(count) # append the current class's predictions for each attack to the all_count list\n","    #print(all_count)\n","\n","    return accuracies, x_test_adv_pre, x_test_adv_eps_5, x_test_adv_eps_10, x_test_adv_eps_50, x_test_adv_eps_95, y_test_adv, all_count\n","\n","\n","\n","# Step 6: Get Statistical Results\n","accu = [] # used to hold the accuracy of each epsilon value per round\n","labeltally = [] # used to hold the total number of correct predictions per round per epsilon value\n","for i in range(0, 10): # do steps 5 and 6, 10 times for averaging purposes\n","    result = getaccuracy_forone_extraction(X_test_substitute, Y_test_substitute) # call the function getaccuracy_forone_extraction\n","    accu.append(result[0]) # append the accuracy results of the current function call to the accu list\n","    labeltally.append(result[7]) # append the all_count results of the current function call to the labeltally list\n","\n","final_accuracies = [] # used to hold the average accuracy of each epsilon value\n","for i in range(0, 4): # loop through each epsilon value\n","    x = (accu[0][i] + accu[1][i] + accu[2][i] + accu[3][i] + accu[4][i] + accu[5][i] + accu[6][i] + accu[7][i] + accu[8][i] + accu[9][i]) / 10 # find average or each attack across all rounds\n","    final_accuracies.append(x)\n","\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Average Accuracy on adversarial test examples with delta = 0.05: {}%\".format(final_accuracies[0]))\n","print(\"Average Accuracy on adversarial test examples with delta = 0.1: {}%\".format(final_accuracies[1]))\n","print(\"Average Accuracy on adversarial test examples with delta = 0.5: {}%\".format(final_accuracies[2]))\n","print(\"Average Accuracy on adversarial test examples with delta = 0.95: {}%\".format(final_accuracies[3]))\n","print()\n","\n","labelaccuracy = [] # used to hold the average value of the total number of correct predictions per epsilon value\n","for j in range(0, 10):\n","    x = []\n","    for i in range(0, 5):\n","        x.append(labeltally[0][j][i] + labeltally[1][j][i] + labeltally[2][j][i] + labeltally[3][j][i] + labeltally[4][j][i] + labeltally[5][j][i] + labeltally[6][j][i]\n","                 + labeltally[7][j][i] + labeltally[8][j][i] + labeltally[9][j][i])\n","    labelaccuracy.append(x)\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][0]) + \"%\")\n","    print(\"Universal Perturbation Method with delta = 0.05 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][1]) + \"%\")\n","    print(\"Universal Perturbation  Method with delta = 0.1 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][2]) + \"%\")\n","    print(\"Universal Perturbation  Method with delta = 0.5 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][3]) + \"%\")\n","    print(\"Universal Perturbation  Method with delta = 0.95 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][4]) + \"%\")\n","    print()\n","\n","accuracies = result[0]\n","x_test_adv_pre = result[1]\n","x_test_adv_eps_5 = result[2]\n","x_test_adv_eps_10 = result[3]\n","x_test_adv_eps_50 = result[4]\n","x_test_adv_eps_95 = result[5]\n","y_test_adv = result[6]\n","\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image DELTA = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(victim_classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(victim_classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(victim_classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(victim_classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(victim_classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples delta = \" + str(eps[i-32]) + \": {}%\".format(round(final_accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=5.0, w_pad=5.0)\n","    plt.show()"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}