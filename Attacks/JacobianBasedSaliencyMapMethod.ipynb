{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JacobianBasedSaliencyMapMethod.ipynb","provenance":[{"file_id":"https://github.com/podschwadt/teaching/blob/master/defend_cnn.ipynb","timestamp":1582598056181}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vsvgCPv17t3u","colab_type":"code","outputId":"56eb8c37-6d14-4665-f72e-0fe5e9ebf66e","executionInfo":{"status":"ok","timestamp":1588015245642,"user_tz":240,"elapsed":22087,"user":{"displayName":"Kushagra Patel","photoUrl":"","userId":"10771576466234813038"}},"colab":{"base_uri":"https://localhost:8080/","height":989}},"source":["%tensorflow_version 1.x\n","!pip install adversarial-robustness-toolbox\n","!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 12.1MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n","Cloning into 'cleverhans'...\n","remote: Enumerating objects: 13501, done.\u001b[K\n","remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n","Receiving objects: 100% (13501/13501), 8.40 MiB | 6.35 MiB/s, done.\n","Resolving deltas: 100% (9494/9494), done.\n","Processing ./cleverhans\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n","\u001b[?25hCollecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n","Collecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n","Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n","Building wheels for collected packages: cleverhans\n","  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=cbabfaba405f4ca10ec9e0727d045cc693e47854341b887504b8a91d6bb41fbf\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-fm5c599e/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n","Successfully built cleverhans\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2uaOYNaj4jck","colab_type":"code","outputId":"779cdf06-cc81-4e69-a80a-a64f06b9f5bd","executionInfo":{"status":"ok","timestamp":1587061988190,"user_tz":240,"elapsed":3460670,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import SaliencyMapMethod\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR 10 dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"  # @param {type:\"string\"}\n","IMAGE_SHAPE = (32, 32)\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE + (3,))]), clip_values=(min_, max_))\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test)\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n","# print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4 and 5 \n","def getaccuracy_forone_extraction(x_test, y_test):\n","    # Step 4: Collect 10 instances of each case from test examples\n","    def exract_ten_classes( data, labels, classes=(0,1,2,3,4,5,6,7,8,9), no_instance=10 ):\n","        x_pre = [] # list to collect the x_test set\n","        y_pre = [] # list to collect the y_test set\n","        for class_label in range(0, 10): # loop through each of the classes\n","            index = random.randint(0, 5000) # randomly choose an index from the x_test, as means of getting different instances from each class\n","            iteration = no_instance # number of instance of each class to collect\n","            while (iteration != 0):\n","                if np.argmax(labels[index]) == classes[class_label]: # check if the current index label matches the specified class label we are looking for\n","                    x_pre.append(data[index]) # add the image to the x_test set\n","                    y_pre.append(int(class_label)) # add the image label to the y_test set\n","                    iteration = iteration - 1 # reduce # of instances by 1\n","                index = index + 1 # go to next index till next label is of the current class\n","        x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","        y = keras.utils.to_categorical( np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","        return x, y\n","\n","    x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test ) # call method to get 10 instances of each class\n","    #print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","          #\"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","    # Step 5: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","    attack_eps_5 = SaliencyMapMethod(classifier=classifier, gamma = 0.05, theta = 0.05) # generate attack with FGSM method with eps = 0.05\n","    x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_5 = classifier.predict(x_test_adv_eps_5) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with gamma = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","    attack_eps_10 = SaliencyMapMethod(classifier=classifier, gamma = 0.1, theta = 0.05) # generate attack with FGSM method with eps = 0.1\n","    x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_10 = classifier.predict(x_test_adv_eps_10) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with gamma = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","    attack_eps_50 = SaliencyMapMethod(classifier=classifier, gamma = 0.5, theta = 0.05) # generate attack with FGSM method with eps = 0.5\n","    x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_50 = classifier.predict(x_test_adv_eps_50) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with gamma = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","    attack_eps_95 = SaliencyMapMethod(classifier=classifier, gamma = 0.95, theta = 0.05) # generate attack with FGSM method with eps = 0.95\n","    x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n","    predictions_eps_95 = classifier.predict(x_test_adv_eps_95) # feed the adversarial examples to the classifier and predict the labels\n","    accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n","    #print(\"Accuracy on adversarial test examples with gamma = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","    accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100] # create a list which holds the accuracy of the classifier with differnt values of epsilon for the FGSM attack\n","\n","    all_count = [] # used to hold the accuracy of each attack on each label, i.e. original, eps = 5, eps 10, eps = 50, eps = 95\n","    for j in range(0, 100, 10): # iterate through each class\n","        count = [0, 0, 0, 0, 0] # used to hold accuracy of each attack for this instance of the label\n","        for i in range(j, j + 10): # loop through each instance of the current class\n","            sample_pre = x_test_adv_pre[i, :] # load the current image from the x set\n","            label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2])))) # predict the label of the original image from x set\n","            sample_post_eps_5 = x_test_adv_eps_5[i, :]\n","            label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","            sample_post_eps_10 = x_test_adv_eps_10[i, :]\n","            label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","            sample_post_eps_50 = x_test_adv_eps_50[i, :]\n","            label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","            sample_post_eps_95 = x_test_adv_eps_95[i, :]\n","            label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","            if (label_pre == np.argmax(y_test_adv[i])): # if's are to update the count list to tally correct predictions\n","                count[0] = count[0] + 1\n","            if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","                count[1] = count[1] + 1\n","            if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","                count[2] = count[2] + 1\n","            if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","                count[3] = count[3] + 1\n","            if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","                count[4] = count[4] + 1\n","        all_count.append(count) # append the current class's predictions for each attack to the all_count list\n","    #print(all_count)\n","\n","    return accuracies, x_test_adv_pre, x_test_adv_eps_5, x_test_adv_eps_10, x_test_adv_eps_50, x_test_adv_eps_95, y_test_adv, all_count\n","\n","\n","\n","# Step 6: Get Statistical Results\n","accu = [] # used to hold the accuracy of each epsilon value per round\n","labeltally = [] # used to hold the total number of correct predictions per round per epsilon value\n","for i in range(0, 10): # do steps 5 and 6, 10 times for averaging purposes\n","    result = getaccuracy_forone_extraction(x_test, y_test) # call the function getaccuracy_forone_extraction\n","    accu.append(result[0]) # append the accuracy results of the current function call to the accu list\n","    labeltally.append(result[7]) # append the all_count results of the current function call to the labeltally list\n","\n","final_accuracies = [] # used to hold the average accuracy of each epsilon value\n","for i in range(0, 4): # loop through each epsilon value\n","    x = (accu[0][i] + accu[1][i] + accu[2][i] + accu[3][i] + accu[4][i] + accu[5][i] + accu[6][i] + accu[7][i] + accu[8][i] + accu[9][i]) / 10 # find average or each attack across all rounds\n","    final_accuracies.append(x)\n","\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Average Accuracy on adversarial test examples with gamma = 0.05: {}%\".format(final_accuracies[0]))\n","print(\"Average Accuracy on adversarial test examples with gamma = 0.1: {}%\".format(final_accuracies[1]))\n","print(\"Average Accuracy on adversarial test examples with gamma = 0.5: {}%\".format(final_accuracies[2]))\n","print(\"Average Accuracy on adversarial test examples with gamma = 0.95: {}%\".format(final_accuracies[3]))\n","print()\n","\n","labelaccuracy = [] # used to hold the average value of the total number of correct predictions per epsilon value\n","for j in range(0, 10):\n","    x = []\n","    for i in range(0, 5):\n","        x.append(labeltally[0][j][i] + labeltally[1][j][i] + labeltally[2][j][i] + labeltally[3][j][i] + labeltally[4][j][i] + labeltally[5][j][i] + labeltally[6][j][i]\n","                 + labeltally[7][j][i] + labeltally[8][j][i] + labeltally[9][j][i])\n","    labelaccuracy.append(x)\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][0]) + \"%\")\n","    print(\"Jacobian Saliency Map Method with gamma = 0.05 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][1]) + \"%\")\n","    print(\"Jacobian Saliency Map  Method with gamma = 0.1 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][2]) + \"%\")\n","    print(\"Jacobian Saliency Map  Method with gamma = 0.5 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][3]) + \"%\")\n","    print(\"Jacobian Saliency Map  Method with gamma = 0.95 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][4]) + \"%\")\n","    print()\n","\n","accuracies = result[0]\n","x_test_adv_pre = result[1]\n","x_test_adv_eps_5 = result[2]\n","x_test_adv_eps_10 = result[3]\n","x_test_adv_eps_50 = result[4]\n","x_test_adv_eps_95 = result[5]\n","y_test_adv = result[6]\n","\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image GAMMA = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples gamma = \" + str(eps[i-32]) + \": {}%\".format(round(final_accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=5.0, w_pad=5.0)\n","    plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","x_train size: 153600000\n","y_train shape: (50000, 10)\n","y_train size: 500000\n","x_test shape: (10000, 32, 32, 3)\n","x_test size: 30720000\n","y_test shape: (10000, 10)\n","y_test size: 100000\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f075ae06f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f075ae06f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f075ae06f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vz_aukCv4UiM","colab_type":"code","colab":{}},"source":["!pip install git+https://github.com/nottombrown/imagenet_stubs\n","!pip install adversarial-robustness-toolbox\n","import imagenet_stubs\n","from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name\n","from art.defences import JpegCompression\n","from art.defences import TotalVarMin\n","from art.defences import GaussianNoise\n","from art.defences import PixelDefend\n","from art.defences import ClassLabels\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pPMKwNqV4aF5","colab_type":"code","colab":{}},"source":["ss = JpegCompression(clip_values=(min_, max_))\n","\n","x_art_def, _ = ss(x_test)\n","x_art_adv_def, _ = ss(x_test_adv_eps_5)\n","\n","# Compute the classifier predictions on the preprocessed inputs:\n","pred_def = classifier.predict(x_art_def)\n","label_def = np.argmax(pred_def, axis=1)[0]\n","confidence_def = pred_def[:, label_def][0]\n","\n","pred_adv_def = classifier.predict(x_art_adv_def)\n","label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n","confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n","\n","print(\"Defense: JPEG Compression \")\n","print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n","print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n","      '- confidence {0:.2f}'.format(confidence_adv_def))\n","plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n"],"execution_count":0,"outputs":[]}]}
