{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8Zeroth-order.ipynb","provenance":[{"file_id":"1wNwZCni24FKNMkBY3mBnYkQ778kszHbA","timestamp":1586726942276},{"file_id":"https://github.com/podschwadt/teaching/blob/master/defend_cnn.ipynb","timestamp":1582598056181}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vsvgCPv17t3u","colab_type":"code","outputId":"58b067e5-b207-4555-c226-db7b06f394b5","executionInfo":{"status":"ok","timestamp":1588105942468,"user_tz":240,"elapsed":18871,"user":{"displayName":"Harnoor Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFpNkqY6f5Zk8692L_ARd3SVyrAmRKxF0IMyc8_w=s64","userId":"00087109453484129771"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%tensorflow_version 1.x\n","!pip install adversarial-robustness-toolbox\n","!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans/\n","!pip install cma"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 16.7MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 13.7MB/s \n","\u001b[?25hRequirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n","Cloning into 'cleverhans'...\n","remote: Enumerating objects: 13501, done.\u001b[K\n","remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n","Receiving objects: 100% (13501/13501), 8.40 MiB | 13.95 MiB/s, done.\n","Resolving deltas: 100% (9494/9494), done.\n","Processing ./cleverhans\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 36.9MB/s \n","\u001b[?25hCollecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n","Collecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n","Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n","Building wheels for collected packages: cleverhans\n","  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=05e636b5afd6ecc900edb8b49f5bd153da076f022d68586f54a510179c9348ad\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-aasy0jnh/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n","Successfully built cleverhans\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n","Collecting cma\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/c0/0a1c41f7cad0a51e07991cf86423d0e6651d035f1fe7dcff48e8858848f2/cma-3.0.3-py2.py3-none-any.whl (230kB)\n","\u001b[K     |████████████████████████████████| 235kB 16.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cma) (1.18.3)\n","Installing collected packages: cma\n","Successfully installed cma-3.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sSaZZITZxE6O","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CT3K5k-fIIZ0","colab_type":"code","outputId":"c0853207-0821-4d1b-de01-3d3b30e59c55","executionInfo":{"status":"ok","timestamp":1587960078727,"user_tz":240,"elapsed":8002461,"user":{"displayName":"Harnoor Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFpNkqY6f5Zk8692L_ARd3SVyrAmRKxF0IMyc8_w=s64","userId":"00087109453484129771"}},"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":626}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import ZooAttack\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = ZooAttack(classifier=classifier)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with max_iter = 20: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = ZooAttack(classifier=classifier, max_iter=40)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with max_iter = 20:: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = ZooAttack(classifier=classifier,max_iter=70)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = ZooAttack(classifier=classifier, max_iter=100)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [20, 40, 70, 100]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image Max_ITER = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with max_iter = 20:: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with max_iter = 40:: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with max_iter = 70:: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with max_iter = 100:: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 20: has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 40: has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 70: has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 100: has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","x_train size: 153600000\n","y_train shape: (50000, 10)\n","y_train size: 500000\n","x_test shape: (10000, 32, 32, 3)\n","x_test size: 30720000\n","y_test shape: (10000, 10)\n","y_test size: 100000\n","\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fab39c032e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fab39c032e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7fab39c032e8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on benign test examples: 94.52000000000001%\n","\n","x_test_adv_pre shape: (100, 32, 32, 3)\n","x_test_adv_pre size: 307200\n","y_test_adv_pre shape: (100, 10)\n","y_test_adv_pre size: 1000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bPk9YdsgUePL","colab_type":"code","outputId":"0b1cc00f-0298-4203-9882-fdb7bf673b17","executionInfo":{"status":"ok","timestamp":1588115824108,"user_tz":240,"elapsed":22,"user":{"displayName":"Harnoor Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFpNkqY6f5Zk8692L_ARd3SVyrAmRKxF0IMyc8_w=s64","userId":"00087109453484129771"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BCisv2vES23rqtTZjP9n2EIphe_1aQxP"}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import ZooAttack\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = ZooAttack(classifier=classifier, max_iter=20)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = ZooAttack(classifier=classifier, max_iter=40)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = ZooAttack(classifier=classifier, max_iter=70)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = ZooAttack(classifier=classifier, max_iter=100)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [20, 40, 70, 100]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image max_iter = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with max_iter = 20: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with max_iter = 40: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with max_iter = 70: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with max_iter = 100: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 20 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 40 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 70 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with max_iter = 100 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"e_wVNCZ8GnLD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"18a51cd7-ed01-4d42-8e62-0317381edec1","executionInfo":{"status":"ok","timestamp":1588118544041,"user_tz":240,"elapsed":862012,"user":{"displayName":"Harnoor Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFpNkqY6f5Zk8692L_ARd3SVyrAmRKxF0IMyc8_w=s64","userId":"00087109453484129771"}}},"source":["!pip install git+https://github.com/nottombrown/imagenet_stubs\n","\n","import imagenet_stubs\n","from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name\n","from art.defences import JpegCompression\n","from art.defences import TotalVarMin\n","from art.defences import GaussianNoise\n","from art.defences import PixelDefend\n","from art.defences import ClassLabels\n","\n","ss = JpegCompression(clip_values=(min_, max_))\n","\n","x_art_def, _ = ss(x_test)\n","x_art_adv_def, _ = ss(x_test_adv_eps_5)\n","\n","# Compute the classifier predictions on the preprocessed inputs:\n","pred_def = classifier.predict(x_art_def)\n","label_def = np.argmax(pred_def, axis=1)[0]\n","confidence_def = pred_def[:, label_def][0]\n","\n","pred_adv_def = classifier.predict(x_art_adv_def)\n","label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n","confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n","\n","print(\"Defense: JPEG Compression \")\n","print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n","print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n","      '- confidence {0:.2f}'.format(confidence_adv_def))\n","plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n","\n","\n","ss = GaussianNoise()\n","\n","x_art_def = ss(x_test)\n","x_art_adv_def = ss(x_test_adv_eps_5)\n","\n","# Compute the classifier predictions on the preprocessed inputs:\n","pred_def = classifier.predict(x_art_def)\n","label_def = np.argmax(pred_def, axis=1)[0]\n","confidence_def = pred_def[:, label_def][0]\n","\n","pred_adv_def = classifier.predict(x_art_adv_def)\n","label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n","confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n","\n","print(\"Defense: Gaussian Noise\")\n","print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n","print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n","      '- confidence {0:.2f}'.format(confidence_adv_def))\n","plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n","\n","ss = TotalVarMin(clip_values=(min_, max_))\n","x_art_def, _ = ss(x_test)\n","x_art_adv_def, _ = ss(x_test_adv_eps_5)\n","\n","# Compute the classifier predictions on the preprocessed inputs:\n","pred_def = classifier.predict(x_art_def)\n","label_def = np.argmax(pred_def, axis=1)[0]\n","confidence_def = pred_def[:, label_def][0]\n","\n","pred_adv_def = classifier.predict(x_art_adv_def)\n","label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n","confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n","\n","print(\"Defense: Total Variance Minimization\")\n","print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n","print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n","      '- confidence {0:.2f}'.format(confidence_adv_def))\n","plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n","\n","\n","ss = ClassLabels()\n","\n","x_art_def = ss(x_test)\n","x_art_adv_def = ss(x_test_adv_eps_5)\n","\n","# Compute the classifier predictions on the preprocessed inputs:\n","pred_def = classifier.predict(x_art_def)\n","label_def = np.argmax(pred_def, axis=1)[0]\n","confidence_def = pred_def[:, label_def][0]\n","\n","pred_adv_def = classifier.predict(x_art_adv_def)\n","label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n","confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n","\n","print(\"Defense: Class Labels Compression \")\n","print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n","print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n","      '- confidence {0:.2f}'.format(confidence_adv_def))\n","plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/nottombrown/imagenet_stubs\n","  Cloning https://github.com/nottombrown/imagenet_stubs to /tmp/pip-req-build-4biy4q1u\n","  Running command git clone -q https://github.com/nottombrown/imagenet_stubs /tmp/pip-req-build-4biy4q1u\n","Building wheels for collected packages: imagenet-stubs\n","  Building wheel for imagenet-stubs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imagenet-stubs: filename=imagenet_stubs-0.0.7-cp36-none-any.whl size=794841 sha256=b55b678a00d0efecff0272101f06b88c808a445a73412e476f38860fafd2c1b0\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-5f2szl5r/wheels/ae/51/e7/c1cfa8692ea864410aa778b169fc7766af073ac52a1bc23301\n","Successfully built imagenet-stubs\n","Installing collected packages: imagenet-stubs\n","Successfully installed imagenet-stubs-0.0.7\n","Defense: JPEG Compression \n","Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.12\n","Prediction of adversarial sample: tench, Tinca tinca - confidence 11.29\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["Defense: Gaussian Noise\n","Prediction of original sample: stingray - confidence 8.21\n","Prediction of adversarial sample: stingray - confidence 5.54\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Defense: Total Variance Minimization\n","Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.56\n","Prediction of adversarial sample: hen - confidence 8.11\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Defense: Class Labels Compression \n","Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.70\n","Prediction of adversarial sample: tiger shark, Galeocerdo cuvieri - confidence 6.70\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}