{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BasicIterativeMethod done.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsvgCPv17t3u",
        "colab_type": "code",
        "outputId": "d43011b5-4963-4e65-efae-616ff8aa5f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 5.6MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 30.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n",
            "Cloning into 'cleverhans'...\n",
            "remote: Enumerating objects: 13501, done.\u001b[K\n",
            "remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n",
            "Receiving objects: 100% (13501/13501), 8.40 MiB | 9.92 MiB/s, done.\n",
            "Resolving deltas: 100% (9494/9494), done.\n",
            "Processing ./cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 6.3MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n",
            "Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=2192a07e3cf8bfabf3e4227beeb83ab01725bbd72990ad663285fd1f093438b0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-45b5lq50/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4O7Qpe_5KzS",
        "colab_type": "code",
        "outputId": "39abf767-9010-4e39-c0a0-43d9529d8246",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.attacks import BasicIterativeMethod\n",
        "from art.classifiers import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "import random\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Load the CIFAR 10 dataset\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n",
        "print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" +\n",
        "      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n",
        "      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n",
        "      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "x_train size: 153600000\n",
            "y_train shape: (50000, 10)\n",
            "y_train size: 500000\n",
            "x_test shape: (10000, 32, 32, 3)\n",
            "x_test size: 30720000\n",
            "y_test shape: (10000, 10)\n",
            "y_test size: 100000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJCjMeHR0dAR",
        "colab_type": "code",
        "outputId": "32a9c4f4-34ae-44d4-a45f-e3f3dcc9ef9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "\n",
        "\n",
        "# Step 2: Load the victim model\n",
        "classifier_url = \"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\"  # @param {type:\"string\"}\n",
        "IMAGE_SHAPE = (32, 32)\n",
        "classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE + (3,))]), clip_values=(min_, max_))\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Evaluate the victim model on the benign dataset\n",
        "predictions = classifier.predict(x_test)\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test)\n",
        "# print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n",
        "\n",
        "\n",
        "\n",
        "# Step 4 and 5\n",
        "def getaccuracy_forone_extraction(x_test, y_test):\n",
        "    # Step 4: Collect 10 instances of each case from test examples\n",
        "    def exract_ten_classes( data, labels, classes=(0,1,2,3,4,5,6,7,8,9), no_instance=10 ):\n",
        "        x_pre = [] # list to collect the x_test set\n",
        "        y_pre = [] # list to collect the y_test set\n",
        "        for class_label in range(0, 10): # loop through each of the classes\n",
        "            index = random.randint(0, 5000) # randomly choose an index from the x_test, as means of getting different instances from each class\n",
        "            iteration = no_instance # number of instance of each class to collect\n",
        "            while (iteration != 0):\n",
        "                if np.argmax(labels[index]) == classes[class_label]: # check if the current index label matches the specified class label we are looking for\n",
        "                    x_pre.append(data[index]) # add the image to the x_test set\n",
        "                    y_pre.append(int(class_label)) # add the image label to the y_test set\n",
        "                    iteration = iteration - 1 # reduce # of instances by 1\n",
        "                index = index + 1 # go to next index till next label is of the current class\n",
        "        x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n",
        "        y = keras.utils.to_categorical( np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n",
        "        return x, y\n",
        "\n",
        "    x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test ) # call method to get 10 instances of each class\n",
        "    #print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n",
        "          #\"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n",
        "\n",
        "\n",
        "    # Step 5: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n",
        "    attack_eps_5 = BasicIterativeMethod(classifier=classifier, eps=0.1, max_iter=100) # generate attack with FGSM method with eps = 0.05\n",
        "    x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n",
        "    predictions_eps_5 = classifier.predict(x_test_adv_eps_5) # feed the adversarial examples to the classifier and predict the labels\n",
        "    accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n",
        "    #print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_5 * 100))\n",
        "\n",
        "    attack_eps_10 = BasicIterativeMethod(classifier=classifier, eps=0.25, max_iter=100) # generate attack with FGSM method with eps = 0.1\n",
        "    x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n",
        "    predictions_eps_10 = classifier.predict(x_test_adv_eps_10) # feed the adversarial examples to the classifier and predict the labels\n",
        "    accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n",
        "    #print(\"Accuracy on adversarial test examples with eps = 0.25: {}%\".format(accuracy_adv_eps_10 * 100))\n",
        "\n",
        "    attack_eps_50 = BasicIterativeMethod(classifier=classifier, eps=0.5, max_iter=100) # generate attack with FGSM method with eps = 0.5\n",
        "    x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n",
        "    predictions_eps_50 = classifier.predict(x_test_adv_eps_50) # feed the adversarial examples to the classifier and predict the labels\n",
        "    accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n",
        "    #print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n",
        "\n",
        "    attack_eps_95 = BasicIterativeMethod(classifier=classifier, eps=0.95, max_iter=100) # generate attack with FGSM method with eps = 0.95\n",
        "    x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre) # generate adversarial examples from the x_test_adv which has 100 examples of 10 images per class\n",
        "    predictions_eps_95 = classifier.predict(x_test_adv_eps_95) # feed the adversarial examples to the classifier and predict the labels\n",
        "    accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv) # calcualte the classifiers accuracy\n",
        "    #print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n",
        "\n",
        "    accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100] # create a list which holds the accuracy of the classifier with differnt values of epsilon for the FGSM attack\n",
        "\n",
        "    all_count = [] # used to hold the accuracy of each attack on each label, i.e. original, eps = 5, eps 10, eps = 50, eps = 95\n",
        "    for j in range(0, 100, 10): # iterate through each class\n",
        "        count = [0, 0, 0, 0, 0] # used to hold accuracy of each attack for this instance of the label\n",
        "        for i in range(j, j + 10): # loop through each instance of the current class\n",
        "            sample_pre = x_test_adv_pre[i, :] # load the current image from the x set\n",
        "            label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2])))) # predict the label of the original image from x set\n",
        "            sample_post_eps_5 = x_test_adv_eps_5[i, :]\n",
        "            label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n",
        "            sample_post_eps_10 = x_test_adv_eps_10[i, :]\n",
        "            label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n",
        "            sample_post_eps_50 = x_test_adv_eps_50[i, :]\n",
        "            label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n",
        "            sample_post_eps_95 = x_test_adv_eps_95[i, :]\n",
        "            label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n",
        "            if (label_pre == np.argmax(y_test_adv[i])): # if's are to update the count list to tally correct predictions\n",
        "                count[0] = count[0] + 1\n",
        "            if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n",
        "                count[1] = count[1] + 1\n",
        "            if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n",
        "                count[2] = count[2] + 1\n",
        "            if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n",
        "                count[3] = count[3] + 1\n",
        "            if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n",
        "                count[4] = count[4] + 1\n",
        "        all_count.append(count) # append the current class's predictions for each attack to the all_count list\n",
        "    #print(all_count)\n",
        "\n",
        "    return accuracies, x_test_adv_pre, x_test_adv_eps_5, x_test_adv_eps_10, x_test_adv_eps_50, x_test_adv_eps_95, y_test_adv, all_count\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f443ff1eef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f443ff1eef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f443ff1eef0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUFOIr8A0exz",
        "colab_type": "code",
        "outputId": "a1737645-8c3f-4f65-fb31-537a663e6ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Step 6: Get Statistical Results\n",
        "accu = [] # used to hold the accuracy of each epsilon value per round\n",
        "labeltally = [] # used to hold the total number of correct predictions per round per epsilon value\n",
        "for i in range(0, 10): # do steps 5 and 6, 10 times for averaging purposes\n",
        "    result = getaccuracy_forone_extraction(x_test, y_test) # call the function getaccuracy_forone_extraction\n",
        "    accu.append(result[0]) # append the accuracy results of the current function call to the accu list\n",
        "    labeltally.append(result[7]) # append the all_count results of the current function call to the labeltally list\n",
        "\n",
        "final_accuracies = [] # used to hold the average accuracy of each epsilon value\n",
        "for i in range(0, 4): # loop through each epsilon value\n",
        "    x = (accu[0][i] + accu[1][i] + accu[2][i] + accu[3][i] + accu[4][i] + accu[5][i] + accu[6][i] + accu[7][i] + accu[8][i] + accu[9][i]) / 10 # find average or each attack across all rounds\n",
        "    final_accuracies.append(x)\n",
        "\n",
        "print()\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n",
        "print(\"Average Accuracy on adversarial test examples with eps = 0.10: {}%\".format(final_accuracies[0]))\n",
        "print(\"Average Accuracy on adversarial test examples with eps = 0.25: {}%\".format(final_accuracies[1]))\n",
        "print(\"Average Accuracy on adversarial test examples with eps = 0.50: {}%\".format(final_accuracies[2]))\n",
        "print(\"Average Accuracy on adversarial test examples with eps = 0.95: {}%\".format(final_accuracies[3]))\n",
        "print()\n",
        "\n",
        "labelaccuracy = [] # used to hold the average value of the total number of correct predictions per epsilon value\n",
        "for j in range(0, 10):\n",
        "    x = []\n",
        "    for i in range(0, 5):\n",
        "        x.append(labeltally[0][j][i] + labeltally[1][j][i] + labeltally[2][j][i] + labeltally[3][j][i] + labeltally[4][j][i] + labeltally[5][j][i] + labeltally[6][j][i]\n",
        "                 + labeltally[7][j][i] + labeltally[8][j][i] + labeltally[9][j][i])\n",
        "    labelaccuracy.append(x)\n",
        "\n",
        "Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n",
        "for i in range(0, 10):\n",
        "    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][0]) + \"%\")\n",
        "    print(\"Basic Iterative Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][1]) + \"%\")\n",
        "    print(\"Basic Iterative Method with eps = 0.25 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][2]) + \"%\")\n",
        "    print(\"Basic Iterative Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][3]) + \"%\")\n",
        "    print(\"Basic Iterative Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition average accuracy of = \" + str(labelaccuracy[i][4]) + \"%\")\n",
        "    print()\n",
        "\n",
        "accuracies = result[0]\n",
        "x_test_adv_pre = result[1]\n",
        "x_test_adv_eps_5 = result[2]\n",
        "x_test_adv_eps_10 = result[3]\n",
        "x_test_adv_eps_50 = result[4]\n",
        "x_test_adv_eps_95 = result[5]\n",
        "y_test_adv = result[6]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on benign test examples: 94.52000000000001%\n",
            "Average Accuracy on adversarial test examples with eps = 0.10: 38.0%\n",
            "Average Accuracy on adversarial test examples with eps = 0.25: 36.5%\n",
            "Average Accuracy on adversarial test examples with eps = 0.50: 36.5%\n",
            "Average Accuracy on adversarial test examples with eps = 0.95: 36.5%\n",
            "\n",
            "Classifier with benign example has Airplane recognition average accuracy of = 98%\n",
            "Basic Iterative Method with eps = 0.10 has Airplane recognition average accuracy of = 41%\n",
            "Basic Iterative Method with eps = 0.25 has Airplane recognition average accuracy of = 41%\n",
            "Basic Iterative Method with eps = 0.50 has Airplane recognition average accuracy of = 41%\n",
            "Basic Iterative Method with eps = 0.95 has Airplane recognition average accuracy of = 41%\n",
            "\n",
            "Classifier with benign example has Automobile recognition average accuracy of = 98%\n",
            "Basic Iterative Method with eps = 0.10 has Automobile recognition average accuracy of = 43%\n",
            "Basic Iterative Method with eps = 0.25 has Automobile recognition average accuracy of = 42%\n",
            "Basic Iterative Method with eps = 0.50 has Automobile recognition average accuracy of = 41%\n",
            "Basic Iterative Method with eps = 0.95 has Automobile recognition average accuracy of = 41%\n",
            "\n",
            "Classifier with benign example has Bird recognition average accuracy of = 97%\n",
            "Basic Iterative Method with eps = 0.10 has Bird recognition average accuracy of = 64%\n",
            "Basic Iterative Method with eps = 0.25 has Bird recognition average accuracy of = 57%\n",
            "Basic Iterative Method with eps = 0.50 has Bird recognition average accuracy of = 57%\n",
            "Basic Iterative Method with eps = 0.95 has Bird recognition average accuracy of = 57%\n",
            "\n",
            "Classifier with benign example has Cat recognition average accuracy of = 78%\n",
            "Basic Iterative Method with eps = 0.10 has Cat recognition average accuracy of = 24%\n",
            "Basic Iterative Method with eps = 0.25 has Cat recognition average accuracy of = 23%\n",
            "Basic Iterative Method with eps = 0.50 has Cat recognition average accuracy of = 24%\n",
            "Basic Iterative Method with eps = 0.95 has Cat recognition average accuracy of = 24%\n",
            "\n",
            "Classifier with benign example has Deer recognition average accuracy of = 95%\n",
            "Basic Iterative Method with eps = 0.10 has Deer recognition average accuracy of = 28%\n",
            "Basic Iterative Method with eps = 0.25 has Deer recognition average accuracy of = 28%\n",
            "Basic Iterative Method with eps = 0.50 has Deer recognition average accuracy of = 28%\n",
            "Basic Iterative Method with eps = 0.95 has Deer recognition average accuracy of = 28%\n",
            "\n",
            "Classifier with benign example has Dog recognition average accuracy of = 88%\n",
            "Basic Iterative Method with eps = 0.10 has Dog recognition average accuracy of = 25%\n",
            "Basic Iterative Method with eps = 0.25 has Dog recognition average accuracy of = 26%\n",
            "Basic Iterative Method with eps = 0.50 has Dog recognition average accuracy of = 26%\n",
            "Basic Iterative Method with eps = 0.95 has Dog recognition average accuracy of = 26%\n",
            "\n",
            "Classifier with benign example has Frog recognition average accuracy of = 99%\n",
            "Basic Iterative Method with eps = 0.10 has Frog recognition average accuracy of = 57%\n",
            "Basic Iterative Method with eps = 0.25 has Frog recognition average accuracy of = 53%\n",
            "Basic Iterative Method with eps = 0.50 has Frog recognition average accuracy of = 53%\n",
            "Basic Iterative Method with eps = 0.95 has Frog recognition average accuracy of = 53%\n",
            "\n",
            "Classifier with benign example has Horse recognition average accuracy of = 99%\n",
            "Basic Iterative Method with eps = 0.10 has Horse recognition average accuracy of = 23%\n",
            "Basic Iterative Method with eps = 0.25 has Horse recognition average accuracy of = 23%\n",
            "Basic Iterative Method with eps = 0.50 has Horse recognition average accuracy of = 23%\n",
            "Basic Iterative Method with eps = 0.95 has Horse recognition average accuracy of = 23%\n",
            "\n",
            "Classifier with benign example has Ship recognition average accuracy of = 94%\n",
            "Basic Iterative Method with eps = 0.10 has Ship recognition average accuracy of = 36%\n",
            "Basic Iterative Method with eps = 0.25 has Ship recognition average accuracy of = 34%\n",
            "Basic Iterative Method with eps = 0.50 has Ship recognition average accuracy of = 34%\n",
            "Basic Iterative Method with eps = 0.95 has Ship recognition average accuracy of = 34%\n",
            "\n",
            "Classifier with benign example has Truck recognition average accuracy of = 97%\n",
            "Basic Iterative Method with eps = 0.10 has Truck recognition average accuracy of = 39%\n",
            "Basic Iterative Method with eps = 0.25 has Truck recognition average accuracy of = 38%\n",
            "Basic Iterative Method with eps = 0.50 has Truck recognition average accuracy of = 38%\n",
            "Basic Iterative Method with eps = 0.95 has Truck recognition average accuracy of = 38%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3fzj5-B0gO-",
        "colab_type": "code",
        "outputId": "363b1670-f362-40c6-ab7b-deee5123df46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Step 7: Plot Results\n",
        "for ind in range(0, 100, 5):\n",
        "    fig = plt.figure(figsize=(16, 16))\n",
        "    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n",
        "    columns = 5\n",
        "    rows = 7\n",
        "    ax = []\n",
        "\n",
        "    ax.append(fig.add_subplot(rows, columns, 1))\n",
        "    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    eps = [0.1, 0.25, 0.5, 0.95]\n",
        "    for i in range(2, 6):\n",
        "        ax.append(fig.add_subplot(rows, columns, i))\n",
        "        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    imageindex = ind\n",
        "    for i in range(5, columns*rows - 6, 5):\n",
        "        sample_pre = x_test_adv_pre[ imageindex, :]\n",
        "        ax.append( fig.add_subplot(rows, columns, i + 1) )\n",
        "        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n",
        "        plt.imshow(sample_pre)\n",
        "\n",
        "        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n",
        "        ax.append( fig.add_subplot(rows, columns, i + 2) )\n",
        "        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n",
        "        plt.imshow(sample_post_eps_5)\n",
        "\n",
        "        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 3))\n",
        "        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n",
        "        plt.imshow(sample_post_eps_10)\n",
        "\n",
        "        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 4))\n",
        "        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n",
        "        plt.imshow(sample_post_eps_50)\n",
        "\n",
        "        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 5))\n",
        "        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n",
        "        plt.imshow(sample_post_eps_95)\n",
        "\n",
        "        imageindex = imageindex + 1\n",
        "\n",
        "\n",
        "    ax.append(fig.add_subplot(rows, columns, 31))\n",
        "    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    for i in range(32, 36):\n",
        "        ax.append(fig.add_subplot(rows, columns, i))\n",
        "        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(final_accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    fig.tight_layout(h_pad=5.0, w_pad=5.0)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9l_Qep2B9KV",
        "colab_type": "code",
        "outputId": "fbf6a1c1-4ce7-43de-d676-3ad7b090cacd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "!pip install git+https://github.com/nottombrown/imagenet_stubs\n",
        "!pip install adversarial-robustness-toolbox\n",
        "import imagenet_stubs\n",
        "from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name\n",
        "from art.defences import JpegCompression\n",
        "from art.defences import TotalVarMin\n",
        "from art.defences import GaussianNoise\n",
        "from art.defences import PixelDefend\n",
        "from art.defences import ClassLabels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nottombrown/imagenet_stubs\n",
            "  Cloning https://github.com/nottombrown/imagenet_stubs to /tmp/pip-req-build-io2n7q_n\n",
            "  Running command git clone -q https://github.com/nottombrown/imagenet_stubs /tmp/pip-req-build-io2n7q_n\n",
            "Building wheels for collected packages: imagenet-stubs\n",
            "  Building wheel for imagenet-stubs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagenet-stubs: filename=imagenet_stubs-0.0.7-cp36-none-any.whl size=794841 sha256=e732ef733586ca7b983759340430e3b1398cecc00030d56d3539b75cc52d608b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e6zg8zrj/wheels/ae/51/e7/c1cfa8692ea864410aa778b169fc7766af073ac52a1bc23301\n",
            "Successfully built imagenet-stubs\n",
            "Installing collected packages: imagenet-stubs\n",
            "Successfully installed imagenet-stubs-0.0.7\n",
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scikit-learn==0.22.1 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.22.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efrBXvNxB_p1",
        "colab_type": "code",
        "outputId": "4736a7c0-b72e-4add-cb55-c49d9a8bfe23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "ss = JpegCompression(clip_values=(min_, max_))\n",
        "\n",
        "x_art_def, _ = ss(x_test)\n",
        "x_art_adv_def, _ = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: JPEG Compression \")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defense: JPEG Compression \n",
            "Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.12\n",
            "Prediction of adversarial sample: tench, Tinca tinca - confidence 10.28\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uc5WzSBCDHe",
        "colab_type": "code",
        "outputId": "81a7cf0c-06d8-4e98-efec-7ac237be7cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "ss = GaussianNoise()\n",
        "\n",
        "x_art_def = ss(x_test)\n",
        "x_art_adv_def = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Gaussian Noise\")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defense: Gaussian Noise\n",
            "Prediction of original sample: stingray - confidence 6.22\n",
            "Prediction of adversarial sample: stingray - confidence 8.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TxY1um2CEHe",
        "colab_type": "code",
        "outputId": "ee7c45b1-1cf0-4fe0-93f4-6b0a5d49bb57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "ss = TotalVarMin(clip_values=(min_, max_))\n",
        "x_art_def, _ = ss(x_test)\n",
        "x_art_adv_def, _ = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Total Variance Minimization\")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defense: Total Variance Minimization\n",
            "Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.90\n",
            "Prediction of adversarial sample: tench, Tinca tinca - confidence 8.57\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsIAxOQwCGlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ss = ClassLabels()\n",
        "\n",
        "x_art_def = ss(x_test)\n",
        "x_art_adv_def = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Class Labels Compression \")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mWgw44CCJSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}