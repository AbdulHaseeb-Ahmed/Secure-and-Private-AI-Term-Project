{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 4NewtonFool.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQoEjUG0tFJC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsvgCPv17t3u",
        "colab_type": "code",
        "outputId": "4cf25057-b2ea-4a2b-f7dd-b34f1f96e79c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Collecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 22.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n",
            "Cloning into 'cleverhans'...\n",
            "remote: Enumerating objects: 13501, done.\u001b[K\n",
            "remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n",
            "Receiving objects: 100% (13501/13501), 8.40 MiB | 11.00 MiB/s, done.\n",
            "Resolving deltas: 100% (9494/9494), done.\n",
            "Processing ./cleverhans\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 8.8MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.3)\n",
            "Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans==3.0.1) (0.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=946ede76c6600abc6e4edb7e68e549f154584dbc9603b54cec053978ef089ade\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_bs3pwrn/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: nose, pycodestyle, mnist, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT3K5k-fIIZ0",
        "colab_type": "code",
        "outputId": "a664debf-51f5-4c12-a7e2-b7be944db41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.attacks import NewtonFool\n",
        "from art.classifiers import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "from art.defences import JpegCompression\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "\n",
        "\n",
        "# Step 1: Load the CIFAR-10 Dataset\n",
        "(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n",
        "print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n",
        "      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n",
        "      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n",
        "      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Load the victim model\n",
        "classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n",
        "IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n",
        "classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Evaluate the victim model on the benign dataset\n",
        "predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: Collect 10 instances of each class from test set\n",
        "def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n",
        "    x_pre = []  # list to collect the x_test set\n",
        "    y_pre = []  # list to collect the y_test set\n",
        "    for class_label in range(0, 10):  # loop through each of the classes\n",
        "        index = random.randint(0, 5000)  # choose an index from the x_test\n",
        "        iteration = no_instance  # number of instance of each class to collect\n",
        "        while (iteration != 0):\n",
        "            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n",
        "                x_pre.append(data[index])  # add the image to the x_test set\n",
        "                y_pre.append(int(class_label))  # add the image label to the y_test set\n",
        "                iteration = iteration - 1  # reduce # of instances by 1\n",
        "            index = index + 1  # go to next index till next label is of the current class\n",
        "    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n",
        "    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n",
        "    return x, y\n",
        "\n",
        "x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n",
        "print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n",
        "      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n",
        "\n",
        "\n",
        "# Step 5: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n",
        "attack_eps_5 = NewtonFool(classifier=classifier)\n",
        "x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n",
        "predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n",
        "accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n",
        "#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n",
        "\n",
        "attack_eps_10 = NewtonFool(classifier=classifier, max_iter=90)\n",
        "x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n",
        "predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n",
        "accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n",
        "#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n",
        "\n",
        "attack_eps_50 = NewtonFool(classifier=classifier, max_iter=100)\n",
        "x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n",
        "predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n",
        "accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n",
        "#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n",
        "\n",
        "attack_eps_95 = NewtonFool(classifier=classifier, max_iter=120)\n",
        "x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n",
        "predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n",
        "accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n",
        "#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n",
        "\n",
        "accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n",
        "\n",
        "# # Step 6 Defence\n",
        "# # Initalize the JpegCompression defence. \n",
        "# # ss = SpatialSmoothing(window_size=3)\n",
        "# ss = JpegCompression(clip_values=(min_, max_))\n",
        "\n",
        "# # Apply the defence to the original input and to the adversarial sample, respectively:\n",
        "# x_art_def, _ = ss(x_test)\n",
        "# x_art_adv_def, _ = ss(x_test)\n",
        "\n",
        "# # Compute the classifier predictions on the preprocessed inputs:\n",
        "# pred_def = classifier.predict(x_art_def)\n",
        "# label_def = np.argmax(pred_def, axis=1)[0]\n",
        "# confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "# pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "# label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "# confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "# # Print the predictions:\n",
        "# print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "# print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "#       '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "\n",
        "# # Show the preprocessed adversarial sample:\n",
        "# plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Step 7: Plot Results\n",
        "for ind in range(0, 100, 5):\n",
        "    fig = plt.figure(figsize=(16, 16))\n",
        "    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n",
        "    columns = 5\n",
        "    rows = 7\n",
        "    ax = []\n",
        "\n",
        "    ax.append(fig.add_subplot(rows, columns, 1))\n",
        "    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    eps = [0.05, 0.1, 0.5, 0.95]\n",
        "    for i in range(2, 6):\n",
        "        ax.append(fig.add_subplot(rows, columns, i))\n",
        "        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    imageindex = ind\n",
        "    for i in range(5, columns*rows - 6, 5):\n",
        "        sample_pre = x_test_adv_pre[ imageindex, :]\n",
        "        ax.append( fig.add_subplot(rows, columns, i + 1) )\n",
        "        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n",
        "        plt.imshow(sample_pre)\n",
        "\n",
        "        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n",
        "        ax.append( fig.add_subplot(rows, columns, i + 2) )\n",
        "        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n",
        "        plt.imshow(sample_post_eps_5)\n",
        "\n",
        "        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 3))\n",
        "        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n",
        "        plt.imshow(sample_post_eps_10)\n",
        "\n",
        "        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 4))\n",
        "        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n",
        "        plt.imshow(sample_post_eps_50)\n",
        "\n",
        "        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n",
        "        ax.append(fig.add_subplot(rows, columns, i + 5))\n",
        "        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n",
        "        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n",
        "        plt.imshow(sample_post_eps_95)\n",
        "\n",
        "        imageindex = imageindex + 1\n",
        "\n",
        "\n",
        "    ax.append(fig.add_subplot(rows, columns, 31))\n",
        "    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    for i in range(32, 36):\n",
        "        ax.append(fig.add_subplot(rows, columns, i))\n",
        "        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Step 9: Data from Results\n",
        "print()\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n",
        "print(\"Accuracy on adversarial test examples with max_iter = default: {}%\".format(accuracies[0]))\n",
        "print(\"Accuracy on adversarial test examples with max_iter = 100: {}%\".format(accuracies[1]))\n",
        "print(\"Accuracy on adversarial test examples with max_iter = 110: {}%\".format(accuracies[2]))\n",
        "print(\"Accuracy on adversarial test examples with max_iter = 120: {}%\".format(accuracies[3]))\n",
        "print()\n",
        "\n",
        "all_count = []\n",
        "for j in range(0, 100, 10):\n",
        "    count = [0, 0, 0, 0, 0]\n",
        "    for i in range(j, j + 10):\n",
        "        sample_pre = x_test_adv_pre[ i, : ]\n",
        "        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n",
        "        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n",
        "        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n",
        "        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n",
        "        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n",
        "        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n",
        "        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n",
        "        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n",
        "        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n",
        "        if (label_pre == np.argmax(y_test_adv[i])):\n",
        "            count[0] = count[0] + 1\n",
        "        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n",
        "            count[1] = count[1] + 1\n",
        "        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n",
        "            count[2] = count[2] + 1\n",
        "        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n",
        "            count[3] = count[3] + 1\n",
        "        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n",
        "            count[4] = count[4] + 1\n",
        "    all_count.append(count)\n",
        "print()\n",
        "\n",
        "Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n",
        "for i in range(0, 10):\n",
        "    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n",
        "    print(\"Fast Gradient Method with eps = 0.05 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n",
        "    print(\"Fast Gradient Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n",
        "    print(\"Fast Gradient Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n",
        "    print(\"Fast Gradient Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K2p7KRk3zmY",
        "colab_type": "code",
        "outputId": "36f2b3eb-c769-43aa-8bec-a19b5e6a2d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install git+https://github.com/nottombrown/imagenet_stubs\n",
        "\n",
        "import imagenet_stubs\n",
        "from imagenet_stubs.imagenet_2012_labels import name_to_label, label_to_name\n",
        "from art.defences import JpegCompression\n",
        "from art.defences import TotalVarMin\n",
        "from art.defences import GaussianNoise\n",
        "from art.defences import PixelDefend\n",
        "from art.defences import ClassLabels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/nottombrown/imagenet_stubs\n",
            "  Cloning https://github.com/nottombrown/imagenet_stubs to /tmp/pip-req-build-6pa5gtd0\n",
            "  Running command git clone -q https://github.com/nottombrown/imagenet_stubs /tmp/pip-req-build-6pa5gtd0\n",
            "Building wheels for collected packages: imagenet-stubs\n",
            "  Building wheel for imagenet-stubs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagenet-stubs: filename=imagenet_stubs-0.0.7-cp36-none-any.whl size=794841 sha256=2a711f9a32b30ed6c6bb5f3e00276a569da214db8add97bc18b72867e3a772e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1vlixde8/wheels/ae/51/e7/c1cfa8692ea864410aa778b169fc7766af073ac52a1bc23301\n",
            "Successfully built imagenet-stubs\n",
            "Installing collected packages: imagenet-stubs\n",
            "Successfully installed imagenet-stubs-0.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-Y_xbug9CUQ",
        "colab_type": "text"
      },
      "source": [
        "###Defense\n",
        "Gaussian Noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxWUph2L854l",
        "colab_type": "code",
        "outputId": "e6f012c9-82b4-47d9-a4b4-bd724e05bc3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "ss = GaussianNoise()\n",
        "\n",
        "x_art_def = ss(x_test)\n",
        "x_art_adv_def = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Gaussian Noise\")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Defense: Gaussian Noise\n",
            "Prediction of original sample: stingray - confidence 9.43\n",
            "Prediction of adversarial sample: great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias - confidence 5.80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc-qgcDk9wtK",
        "colab_type": "text"
      },
      "source": [
        "Total Variance Minimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyY4WNc26V3p",
        "colab_type": "code",
        "outputId": "59a1c5d2-0cd1-4b5c-e4c0-7ee8c7312107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "source": [
        "ss = TotalVarMin(clip_values=(min_, max_))\n",
        "x_art_def, _ = ss(x_test)\n",
        "x_art_adv_def, _ = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Total Variance Minimization\")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defense: Total Variance Minimization\n",
            "Prediction of original sample: hen - confidence 6.92\n",
            "Prediction of adversarial sample: hen - confidence 12.98\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AC9WUCK92W6",
        "colab_type": "text"
      },
      "source": [
        "JPEG Compression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxBwRMCL7U3n",
        "colab_type": "code",
        "outputId": "cbbc825a-e923-4b98-fe32-65eed8da2174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "source": [
        "ss = JpegCompression(clip_values=(min_, max_))\n",
        "x_art_def, _ = ss(x_test)\n",
        "x_art_adv_def, _ = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: JPEG Compression\")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defense: JPEG Compression\n",
            "Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.12\n",
            "Prediction of adversarial sample: tench, Tinca tinca - confidence 10.59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcEAAAHBCAYAAAARuwDoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAHFUlEQVR4nO3dsWrDMBRA0ark/39ZHUuGFiOChXXPWU1AcYbLG6I35pxfAFD0vfsAALCLCAKQJYIAZIkgAFkiCECWCAKQ9frv4RjD/ycAeLQ55/jrmUkQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAsl67DwDwayx+bn70FHSYBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCAreoH26iW9q0693PfO93jqO+Sd35l7mQQByBJBALJEEIAsEQQgSwQByBJBALJEEIAsEQQgSwQByBJBALJEEIAsEQQgSwQByIpukeAz3PgPPJtJEIAsEQQgSwQByBJBALJEEIAsEQQgSwQByBJBALJEEIAsEQQgSwQByBJBALIOuEB77D7ABXee0aXWAFeZBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIEkEAskQQgCwRBCBLBAHIOmCLxBO2JqxskVj9XjZWAFxlEgQgSwQByBJBALJEEIAsEQQgSwQByBJBALJEEIAsEQQgSwQByBJBALJEEIAsEQQg64AtEk9w57YFmx0ArjIJApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApAlggBkiSAAWSIIQJYIApA15py7zwAAW5gEAcgSQQCyRBCALBEEIEsEAcgSQQCyfgDC4hiFILF7CAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhVVWOJXJPAY",
        "colab_type": "text"
      },
      "source": [
        "Pixel Defend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCkmd4QxJS_p",
        "colab_type": "code",
        "outputId": "f3e1beee-84cd-438b-df4e-4e49bc436c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        }
      },
      "source": [
        "ss = ClassLabels()\n",
        "\n",
        "x_art_def = ss(x_test)\n",
        "x_art_adv_def = ss(x_test_adv_eps_5)\n",
        "\n",
        "# Compute the classifier predictions on the preprocessed inputs:\n",
        "pred_def = classifier.predict(x_art_def)\n",
        "label_def = np.argmax(pred_def, axis=1)[0]\n",
        "confidence_def = pred_def[:, label_def][0]\n",
        "\n",
        "pred_adv_def = classifier.predict(x_art_adv_def)\n",
        "label_adv_def = np.argmax(pred_adv_def, axis=1)[0]\n",
        "confidence_adv_def = pred_adv_def[:, label_adv_def][0]\n",
        "\n",
        "print(\"Defense: Class Labels Compression \")\n",
        "print('Prediction of original sample:', label_to_name(label_def), '- confidence {0:.2f}'.format(confidence_def))\n",
        "print('Prediction of adversarial sample:', label_to_name(label_adv_def), \n",
        "      '- confidence {0:.2f}'.format(confidence_adv_def))\n",
        "plt.figure(figsize=(8,8)); plt.imshow(x_art_adv_def[0][..., ::-1] / 255); plt.axis('off'); plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defense: Class Labels Compression \n",
            "Prediction of original sample: tiger shark, Galeocerdo cuvieri - confidence 6.70\n",
            "Prediction of adversarial sample: tiger shark, Galeocerdo cuvieri - confidence 6.70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}