{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNNSectionFinal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aFF16_-wbdv",
        "colab_type": "code",
        "outputId": "f7d852ed-d215-49e3-b08a-27a3c9a7fc10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "#!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting cleverhans\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hCollecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 47.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n",
            "Collecting mnist~=0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans) (0.7.0)\n",
            "Collecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Installing collected packages: nose, mnist, pycodestyle, cleverhans\n",
            "Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n",
            "Collecting adversarial-robustness-toolbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT3K5k-fIIZ0",
        "colab_type": "code",
        "outputId": "f3507eb2-24d1-4c6d-86d8-c165a62a8c08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, AveragePooling1D, Flatten, Reshape, TimeDistributed\n",
        "from keras.layers import LSTM\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "x_train shape: (25000,)\n",
            "x_test shape: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQwEVhtNk3Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_to_index = imdb.get_word_index()\n",
        "index_to_word = {v: k for k, v in word_to_index.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t-NeuEhk4tw",
        "colab_type": "code",
        "outputId": "3dbe1873-6b06-41bc-dddc-04b42fed604c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(x_train[0])\n",
        "print(\" \".join([index_to_word[x] for x in x_train[0]]))\n",
        "print(\"Min value: \", min(y_train), \"Max value: \", max(y_train) )"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but pratfalls to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other tricky in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of 'n odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
            "Min value:  0 Max value:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZi82VE9hXQ8",
        "colab_type": "code",
        "outputId": "a127cbf9-9082-4f28-dc80-37073d913b91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[0]])\n",
        "print(decoded_review)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts1Hwqyyk46P",
        "colab_type": "code",
        "outputId": "8bbb47cb-f621-4bec-e298-7a056cac7e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "average_length = np.mean([len(x) for x in x_train])\n",
        "median_length = sorted([len(x) for x in x_train])[len(x_train) // 2]\n",
        "\n",
        "print(\"Average sequence length: \", average_length)\n",
        "print(\"Median sequence length: \", median_length)\n",
        "\n",
        "max_sequence_length = 80"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average sequence length:  238.71364\n",
            "Median sequence length:  178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suvbsNaBk5F1",
        "colab_type": "code",
        "outputId": "d80dd818-120e-48dc-e9a5-c75616ab56a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 80)\n",
            "x_test shape: (25000, 80)\n",
            "y_train shape: (25000,)\n",
            "y_test shape: (25000,)\n",
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mReGWAkU1lq2",
        "colab_type": "code",
        "outputId": "6b1ae359-f819-4711-de13-4ca87f4e8470",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)\n",
        "print(y_train[0])\n",
        "print(y_test[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train shape: (25000, 2)\n",
            "y_test shape: (25000, 2)\n",
            "[0. 1.]\n",
            "[1. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhfFvGwjh_la",
        "colab_type": "code",
        "outputId": "4b068391-d276-48f0-bd20-e8c2f2052d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[0]])\n",
        "print(decoded_review)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that played the ? of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH2-fIeSk5Rz",
        "colab_type": "code",
        "outputId": "cd17a1a2-268c-449a-e8c8-d08b96ce22f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "from keras.layers import  AveragePooling2D\n",
        "\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 80, input_length=80,mask_zero=True))\n",
        "model.add(LSTM(80, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "# model.add(AveragePooling2D(pool_size=4, strides=None, padding='valid', data_format='channels_last'))\n",
        "# AvgPoolinD3\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 80, 80)            1600000   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 80)                51520     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 162       \n",
            "=================================================================\n",
            "Total params: 1,651,682\n",
            "Trainable params: 1,651,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjwcX2b1k5di",
        "colab_type": "code",
        "outputId": "96e725eb-052f-48d3-ce71-9930265a3185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "print('Train...')\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=15, validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/15\n",
            "25000/25000 [==============================] - 88s 4ms/step - loss: 0.4581 - accuracy: 0.7822 - val_loss: 0.4029 - val_accuracy: 0.8228\n",
            "Epoch 2/15\n",
            "25000/25000 [==============================] - 88s 4ms/step - loss: 0.3017 - accuracy: 0.8786 - val_loss: 0.3770 - val_accuracy: 0.8389\n",
            "Epoch 3/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.2319 - accuracy: 0.9090 - val_loss: 0.4090 - val_accuracy: 0.8300\n",
            "Epoch 4/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.1676 - accuracy: 0.9370 - val_loss: 0.4440 - val_accuracy: 0.8278\n",
            "Epoch 5/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.1381 - accuracy: 0.9484 - val_loss: 0.5299 - val_accuracy: 0.8220\n",
            "Epoch 6/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.1016 - accuracy: 0.9645 - val_loss: 0.6075 - val_accuracy: 0.8207\n",
            "Epoch 7/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0753 - accuracy: 0.9752 - val_loss: 0.6408 - val_accuracy: 0.8182\n",
            "Epoch 8/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0620 - accuracy: 0.9787 - val_loss: 0.7384 - val_accuracy: 0.8166\n",
            "Epoch 9/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0478 - accuracy: 0.9836 - val_loss: 0.8798 - val_accuracy: 0.8097\n",
            "Epoch 10/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0463 - accuracy: 0.9847 - val_loss: 0.8350 - val_accuracy: 0.8077\n",
            "Epoch 11/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 1.0145 - val_accuracy: 0.8078\n",
            "Epoch 12/15\n",
            "25000/25000 [==============================] - 88s 4ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 1.0328 - val_accuracy: 0.8121\n",
            "Epoch 13/15\n",
            "25000/25000 [==============================] - 88s 4ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.9650 - val_accuracy: 0.8090\n",
            "Epoch 14/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.9664 - val_accuracy: 0.8093\n",
            "Epoch 15/15\n",
            "25000/25000 [==============================] - 87s 3ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 1.0863 - val_accuracy: 0.8102\n",
            "25000/25000 [==============================] - 16s 621us/step\n",
            "Test score: 1.0862999961832165\n",
            "Test accuracy: 0.8102399706840515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-uqSR2ak5ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"Colab_LSTM_Model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tlf3KomFvtn-",
        "colab_type": "code",
        "outputId": "3c8c8789-0711-4007-d89d-f29562db9c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Creating Attack\n",
        "#Preparing Train and Test Subet set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train_sub, _,y_train_sub,_ = train_test_split(x_train, y_train, stratify=y_train, train_size=.08, shuffle = True,)\n",
        "x_test_sub, _, y_test_sub,_ = train_test_split(x_test, y_test, stratify=y_train, train_size=.004, shuffle = True,)\n",
        "\n",
        "print('Training set size:',x_train_sub.shape)\n",
        "print('Test set size',x_test_sub.shape)\n",
        "\n",
        "\n",
        "def jacobianFun(x):\n",
        "  \"\"\"\n",
        "  Calculate jacobian of logits wrt input.\n",
        "  \"\"\"\n",
        "  x = tf.convert_to_tensor(x,dtype=tf.float32)\n",
        "  x = tf.expand_dims(x,0)\n",
        "\n",
        "  with tf.GradientTape(watch_accessed_variables=False, persistent=True) as tape:\n",
        "    tape.watch(e.variables)\n",
        "    y = model(x)\n",
        "\n",
        "  return tf.squeeze(tape.jacobian(y, e.variables, parallel_iterations=100, experimental_use_pfor=False))\n",
        "  "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set size: (2000, 80)\n",
            "Test set size (100, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnquW92BJQZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adversarial Attack\n",
        "def imdb_attack(f, x, D=np.array(list(word_index.values()),dtype='int64'), max_iter=100):\n",
        "  y = f.predict(x)\n",
        "  y = 0 if (y[0] <= 0.5) else 1\n",
        "\n",
        "  x_adversarial = x.copy()\n",
        "\n",
        "  ad_prediction = convert_to_label(f.predict(x_adversarial))\n",
        "\n",
        "  jacobian = jacobianFun(np.squeeze(x))\n",
        "\n",
        "  iteration = 0\n",
        "\n",
        "  while ad_prediction == y:\n",
        "\n",
        "    iteration += 1\n",
        "\n",
        "    if iteration > max_iter:\n",
        "      break\n",
        "\n",
        "    i = np.random.randint(0,80,1)[0]\n",
        "\n",
        "    j_x = jacobian[i]\n",
        "\n",
        "    z = tf.argmin(np.sign(D - x_adversarial[0][i])) #+ 1 #b/c dictionary starts on index 1\n",
        "\n",
        "    w = np.abs(z - np.sign(j_x[i]))\n",
        "\n",
        "    if w==None: break \n",
        "\n",
        "    if not w < max_features:\n",
        "      continue\n",
        "    \n",
        "    x_adversarial[0][i]=w\n",
        "\n",
        "    ad_prediction = convert_to_label(f.predict(x_adversarial))\n",
        "\n",
        "\n",
        "  if ad_prediction != y:\n",
        "    print('Adversarial EXAMPLE Created in ',iteration,'Iterations')\n",
        "\n",
        "  return x_adversarial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EqOW5wsJTQp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "b559936d-c582-4585-819d-7ed4dca10365"
      },
      "source": [
        "#creting adversarial examples\n",
        "adversarial_example = np.array([imdb_attack(model,np.expand_dims(i,0)) for i in x_test_sub]).squeeze()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-67e446871fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madversarial_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimdb_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test_sub\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-67e446871fd9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madversarial_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimdb_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_test_sub\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-971f2e4a4b78>\u001b[0m in \u001b[0;36mimdb_attack\u001b[0;34m(f, x, D, max_iter)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimdb_attack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mx_adversarial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDX30i7OJU7B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changes in sentences\n",
        "for i in range(len(adversarial_example)):\n",
        "  print('Sentence ',i,'Original')\n",
        "  show_sentence(x_test_sub[i])\n",
        "  print('\\nSentence ',i,'Adversarial')\n",
        "  show_sentence(adversarial_example[i])\n",
        "  print('----------------------------------------------------------\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wazdcetJczV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#testing model on adversarial examples\n",
        "print(model.evaluate(x_test_sub,y_test_sub,batch_size=batch_size))\n",
        "print(model.evaluate(adversarial_example, y_test_sub, batch_size=batch_size)) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}