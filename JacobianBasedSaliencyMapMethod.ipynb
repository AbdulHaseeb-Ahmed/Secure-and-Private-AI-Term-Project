{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JacobianBasedSaliencyMapMethod.ipynb","provenance":[{"file_id":"https://github.com/podschwadt/teaching/blob/master/defend_cnn.ipynb","timestamp":1582598056181}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"vsvgCPv17t3u","colab_type":"code","outputId":"807f7014-9e56-4e0c-f318-fa2d0b405920","executionInfo":{"status":"ok","timestamp":1586465053188,"user_tz":240,"elapsed":14111,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":986}},"source":["%tensorflow_version 1.x\n","!pip install adversarial-robustness-toolbox\n","!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 4.6MB/s \n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 17.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.6)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n","Cloning into 'cleverhans'...\n","remote: Enumerating objects: 13501, done.\u001b[K\n","remote: Total 13501 (delta 0), reused 0 (delta 0), pack-reused 13501\u001b[K\n","Receiving objects: 100% (13501/13501), 8.40 MiB | 29.57 MiB/s, done.\n","Resolving deltas: 100% (9493/9493), done.\n","Processing ./cleverhans\n","Collecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 4.6MB/s \n","\u001b[?25hCollecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (3.2.1)\n","Collecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (1.18.2)\n","Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.9.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from cleverhans==3.0.1) (0.14.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (1.2.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.4.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.1)\n","Requirement already satisfied: cloudpickle>=1.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.12.0)\n","Requirement already satisfied: gast>=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (0.3.3)\n","Building wheels for collected packages: cleverhans\n","  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cleverhans: filename=cleverhans-3.0.1-cp36-none-any.whl size=253453 sha256=461ce8f8da35ae1757776a08387e1b6ea665e671be43885cc95e3c59555bdbe2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-qyax02v0/wheels/d1/6b/1d/5cf7b3ca4c0cfc7f845628b8ed46366ab5f4f56b5483e9db7f\n","Successfully built cleverhans\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CT3K5k-fIIZ0","colab_type":"code","outputId":"198333f2-3ad8-4598-88da-e8a30e2ff866","executionInfo":{"status":"ok","timestamp":1586465351202,"user_tz":240,"elapsed":286956,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1vlrOggr_gp1RYxQ2LQi10YaQhoeNzGT4"}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import SaliencyMapMethod\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = SaliencyMapMethod(classifier=classifier, gamma=0.05)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = SaliencyMapMethod(classifier=classifier, gamma=0.1)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = SaliencyMapMethod(classifier=classifier, gamma=0.5)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = SaliencyMapMethod(classifier=classifier, gamma=0.95)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.05 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()\n"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ZZILnDgstHWn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19FquF3dWjSfS8Tpi_n4T0--u8qxtFQKd"},"outputId":"5191adac-3d88-4fab-a997-c84231ce2742","executionInfo":{"status":"ok","timestamp":1586465688320,"user_tz":240,"elapsed":280930,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import SaliencyMapMethod\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = SaliencyMapMethod(classifier=classifier, theta=0.05)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = SaliencyMapMethod(classifier=classifier, theta=0.1)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = SaliencyMapMethod(classifier=classifier, theta=0.5)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = SaliencyMapMethod(classifier=classifier, theta=0.95)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.05 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()\n"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"ScypofDTtR4c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HB9i5anBGPcIkfcLUgiwmJKee3eIyN7z"},"outputId":"f22255cc-cc59-4cd8-a5a6-b37e17bf8774","executionInfo":{"status":"ok","timestamp":1586465935846,"user_tz":240,"elapsed":242058,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import SaliencyMapMethod\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = SaliencyMapMethod(classifier=classifier, gamma=0.5, theta=0.1)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = SaliencyMapMethod(classifier=classifier, gamma=0.5, theta=0.9)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = SaliencyMapMethod(classifier=classifier, gamma=0.5, theta=-0.1)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = SaliencyMapMethod(classifier=classifier, gamma=0.5, theta=-0.9)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.05 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Cc45lihRvIln","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1oRQo_z_EO1SJ3lcjHFYPAIalth2uRIRS"},"outputId":"6dd3b789-12fc-4081-a0ec-f319dbd99e76","executionInfo":{"status":"ok","timestamp":1586466427915,"user_tz":240,"elapsed":198080,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.attacks import SaliencyMapMethod\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train, y_train), (x_test, y_test), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train shape: \" + str(x_train.shape) + \"\\n\" + \"x_train size: \" + str(x_train.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train shape: \" + str(y_train.shape) + \"\\n\" + \"y_train size: \" + str(y_train.size) + \"\\n\" +\n","      \"x_test shape: \" + str(x_test.shape) + \"\\n\" + \"x_test size: \" + str(x_test.size) + \"\\n\" +\n","      \"y_test shape: \" + str(y_test.shape) + \"\\n\" + \"y_test size: \" + str(y_test.size) + \"\\n\")\n","print()\n","\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = classifier.predict(x_test) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1)) / len(y_test) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples: {}%\\n\".format(accuracy_benign * 100))\n","\n","\n","\n","# Step 4: Collect 10 instances of each class from test set\n","def exract_ten_classes(data, labels, classes=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), no_instance=10):\n","    x_pre = []  # list to collect the x_test set\n","    y_pre = []  # list to collect the y_test set\n","    for class_label in range(0, 10):  # loop through each of the classes\n","        index = random.randint(0, 5000)  # choose an index from the x_test\n","        iteration = no_instance  # number of instance of each class to collect\n","        while (iteration != 0):\n","            if np.argmax(labels[index]) == classes[class_label]:  # check if the current index label matches the specified class label we are looking for\n","                x_pre.append(data[index])  # add the image to the x_test set\n","                y_pre.append(int(class_label))  # add the image label to the y_test set\n","                iteration = iteration - 1  # reduce # of instances by 1\n","            index = index + 1  # go to next index till next label is of the current class\n","    x = np.asarray(x_pre)  # append all 100, 10 of each class, images together\n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  # append all 100, 10 of each class, labels together and do one hot encoding\n","    return x, y\n","\n","x_test_adv_pre, y_test_adv = exract_ten_classes( x_test, y_test )\n","print(\"x_test_adv_pre shape: \" + str(x_test_adv_pre.shape) + \"\\n\" + \"x_test_adv_pre size: \" + str(x_test_adv_pre.size) + \"\\n\" +\n","      \"y_test_adv_pre shape: \" + str(y_test_adv.shape) + \"\\n\" + \"y_test_adv_pre size: \" + str(y_test_adv.size) + \"\\n\")\n","\n","\n","# Step 6: Generate adversarial test examples and Evaluate the ART classifier on adversarial test examples\n","attack_eps_5 = SaliencyMapMethod(classifier=classifier, gamma=0.05, theta=0.5)\n","x_test_adv_eps_5 = attack_eps_5.generate(x=x_test_adv_pre)\n","predictions_eps_5 = classifier.predict(x_test_adv_eps_5)\n","accuracy_adv_eps_5 = np.sum(np.argmax(predictions_eps_5, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracy_adv_eps_5 * 100))\n","\n","attack_eps_10 = SaliencyMapMethod(classifier=classifier, gamma=0.1, theta=0.5)\n","x_test_adv_eps_10 = attack_eps_10.generate(x=x_test_adv_pre)\n","predictions_eps_10 = classifier.predict(x_test_adv_eps_10)\n","accuracy_adv_eps_10 = np.sum(np.argmax(predictions_eps_10, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracy_adv_eps_10 * 100))\n","\n","attack_eps_50 = SaliencyMapMethod(classifier=classifier, gamma=0.5, theta=0.5)\n","x_test_adv_eps_50 = attack_eps_50.generate(x=x_test_adv_pre)\n","predictions_eps_50 = classifier.predict(x_test_adv_eps_50)\n","accuracy_adv_eps_50 = np.sum(np.argmax(predictions_eps_50, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracy_adv_eps_50 * 100))\n","\n","attack_eps_95 = SaliencyMapMethod(classifier=classifier, gamma=0.95, theta=0.5)\n","x_test_adv_eps_95 = attack_eps_95.generate(x=x_test_adv_pre)\n","predictions_eps_95 = classifier.predict(x_test_adv_eps_95)\n","accuracy_adv_eps_95 = np.sum(np.argmax(predictions_eps_95, axis=1) == np.argmax(y_test_adv, axis=1)) / len(y_test_adv)\n","#print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracy_adv_eps_95 * 100))\n","\n","accuracies = [accuracy_adv_eps_5 * 100, accuracy_adv_eps_10 * 100, accuracy_adv_eps_50 * 100, accuracy_adv_eps_95 * 100]\n","\n","\n","# Step 7: Plot Results\n","for ind in range(0, 100, 5):\n","    fig = plt.figure(figsize=(16, 16))\n","    fig.suptitle('Adversarial Attack On Victim Model', fontsize=24, fontweight='bold')\n","    columns = 5\n","    rows = 7\n","    ax = []\n","\n","    ax.append(fig.add_subplot(rows, columns, 1))\n","    plt.text(0.38, 0.1, 'Original Image', fontsize=10, fontweight='bold')\n","    plt.axis('off')\n","\n","    eps = [0.05, 0.1, 0.5, 0.95]\n","    for i in range(2, 6):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.1, 'Adversarial Image EPS = ' + str(eps[i - 2]), fontsize=10, fontweight='bold')\n","        plt.axis('off')\n","\n","    imageindex = ind\n","    for i in range(5, columns*rows - 6, 5):\n","        sample_pre = x_test_adv_pre[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 1) )\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_pre))\n","        plt.imshow(sample_pre)\n","\n","        sample_post_eps_5 = x_test_adv_eps_5[ imageindex, :]\n","        ax.append( fig.add_subplot(rows, columns, i + 2) )\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_5))\n","        plt.imshow(sample_post_eps_5)\n","\n","        sample_post_eps_10 = x_test_adv_eps_10[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 3))\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_10))\n","        plt.imshow(sample_post_eps_10)\n","\n","        sample_post_eps_50 = x_test_adv_eps_50[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 4))\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_50))\n","        plt.imshow(sample_post_eps_50)\n","\n","        sample_post_eps_95 = x_test_adv_eps_95[imageindex, :]\n","        ax.append(fig.add_subplot(rows, columns, i + 5))\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        plt.text(33, 18, 'Data:\\nTrue Label = %d\\nPredicted Label = %d' % (np.argmax(y_test_adv[imageindex]), label_post_eps_95))\n","        plt.imshow(sample_post_eps_95)\n","\n","        imageindex = imageindex + 1\n","\n","\n","    ax.append(fig.add_subplot(rows, columns, 31))\n","    plt.text(0.0, 0.5, \"Accuracy on benign test examples: {}%\".format(round(accuracy_benign * 100),2), fontsize=8, fontweight='bold')\n","    plt.axis('off')\n","\n","    for i in range(32, 36):\n","        ax.append(fig.add_subplot(rows, columns, i))\n","        plt.text(0.0, 0.5, \"Accuracy on test examples eps = \" + str(eps[i-32]) + \": {}%\".format(round(accuracies[i-32]), 2), fontsize=8, fontweight='bold')\n","        plt.axis('off')\n","\n","    fig.tight_layout(h_pad=4.0, w_pad=4.0)\n","    plt.show()\n","\n","\n","# Step 9: Data from Results\n","print()\n","print(\"Accuracy on benign test examples: {}%\".format(accuracy_benign * 100))\n","print(\"Accuracy on adversarial test examples with eps = 0.05: {}%\".format(accuracies[0]))\n","print(\"Accuracy on adversarial test examples with eps = 0.1: {}%\".format(accuracies[1]))\n","print(\"Accuracy on adversarial test examples with eps = 0.5: {}%\".format(accuracies[2]))\n","print(\"Accuracy on adversarial test examples with eps = 0.95: {}%\".format(accuracies[3]))\n","print()\n","\n","all_count = []\n","for j in range(0, 100, 10):\n","    count = [0, 0, 0, 0, 0]\n","    for i in range(j, j + 10):\n","        sample_pre = x_test_adv_pre[ i, : ]\n","        label_pre = np.argmax(classifier.predict(sample_pre.reshape((1, sample_pre.shape[0], sample_pre.shape[1], sample_pre.shape[2]))))\n","        sample_post_eps_5 = x_test_adv_eps_5[ i, : ]\n","        label_post_eps_5 = np.argmax(classifier.predict(sample_post_eps_5.reshape((1, sample_post_eps_5.shape[0], sample_post_eps_5.shape[1], sample_post_eps_5.shape[2]))))\n","        sample_post_eps_10 = x_test_adv_eps_10[ i, : ]\n","        label_post_eps_10 = np.argmax(classifier.predict(sample_post_eps_10.reshape((1, sample_post_eps_10.shape[0], sample_post_eps_10.shape[1], sample_post_eps_10.shape[2]))))\n","        sample_post_eps_50 = x_test_adv_eps_50[ i, : ]\n","        label_post_eps_50 = np.argmax(classifier.predict(sample_post_eps_50.reshape((1, sample_post_eps_50.shape[0], sample_post_eps_50.shape[1], sample_post_eps_50.shape[2]))))\n","        sample_post_eps_95 = x_test_adv_eps_95[ i, : ]\n","        label_post_eps_95 = np.argmax(classifier.predict(sample_post_eps_95.reshape((1, sample_post_eps_95.shape[0], sample_post_eps_95.shape[1], sample_post_eps_95.shape[2]))))\n","        if (label_pre == np.argmax(y_test_adv[i])):\n","            count[0] = count[0] + 1\n","        if (label_post_eps_5 == np.argmax(y_test_adv[i])):\n","            count[1] = count[1] + 1\n","        if (label_post_eps_10 == np.argmax(y_test_adv[i])):\n","            count[2] = count[2] + 1\n","        if (label_post_eps_50 == np.argmax(y_test_adv[i])):\n","            count[3] = count[3] + 1\n","        if (label_post_eps_95 == np.argmax(y_test_adv[i])):\n","            count[4] = count[4] + 1\n","    all_count.append(count)\n","print()\n","\n","Labels = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]\n","for i in range(0, 10):\n","    print(\"Classifier with benign example has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][0] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.05 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][1] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.10 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][2] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.50 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][3] / 10) * 100) + \"%\")\n","    print(\"Fast Gradient Method with eps = 0.95 has \" + str(Labels[i]) + \" recognition accuracy of = \" + str((all_count[i][4] / 10) * 100) + \"%\")\n","    print()\n"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}