{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AttackTransferability.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"npr2GqEfaWPP","colab_type":"code","outputId":"74cc4d66-3515-4ee8-d367-c6c026b543b9","executionInfo":{"status":"ok","timestamp":1588362817056,"user_tz":240,"elapsed":23673,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iQ2PmsY283WU","colab_type":"code","outputId":"c78f2f25-1156-460c-91a5-a4a6b384f307","executionInfo":{"status":"ok","timestamp":1588362830027,"user_tz":240,"elapsed":15990,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":816}},"source":["%tensorflow_version 1.x\n","#!git clone https://github.com/tensorflow/cleverhans.git\n","!pip install cleverhans\n","!pip install adversarial-robustness-toolbox"],"execution_count":2,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","Collecting cleverhans\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/a0/f0b4386b719f343c4ed3e13cd7792a7a7a4674566ca9b2b34a09b7424220/cleverhans-3.0.1-py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 8.9MB/s \n","\u001b[?25hCollecting nose\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n","\u001b[K     |████████████████████████████████| 163kB 43.6MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-probability in /tensorflow-1.15.2/python3.6 (from cleverhans) (0.7.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.4.1)\n","Collecting pycodestyle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/0c/04a353e104d2f324f8ee5f4b32012618c1c86dd79e52a433b64fceed511b/pycodestyle-2.5.0-py2.py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.8MB/s \n","\u001b[?25hCollecting mnist~=0.2\n","  Downloading https://files.pythonhosted.org/packages/c6/c4/5db3bfe009f8d71f1d532bbadbd0ec203764bba3a469e4703a889db8e5e0/mnist-0.2.2-py2.py3-none-any.whl\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from cleverhans) (1.18.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from cleverhans) (3.2.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.12.0)\n","Requirement already satisfied: cloudpickle>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->cleverhans) (2.4.7)\n","Installing collected packages: nose, pycodestyle, mnist, cleverhans\n","Successfully installed cleverhans-3.0.1 mnist-0.2.2 nose-1.3.7 pycodestyle-2.5.0\n","Collecting adversarial-robustness-toolbox\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/b5/7c7ef44bd2729140930612b4d10af2dbcfa0ca6c9592251c490100b4753a/adversarial_robustness_toolbox-1.2.0-py3-none-any.whl (486kB)\n","\u001b[K     |████████████████████████████████| 491kB 9.1MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n","Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n","Collecting scikit-learn==0.22.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/48/e9fa9e252abcd1447eff6f9257636af31758a6e46fd5ce5d3c879f6907cb/scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 12.0MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n","Installing collected packages: scikit-learn, adversarial-robustness-toolbox\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed adversarial-robustness-toolbox-1.2.0 scikit-learn-0.22.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8DrTwTGfBazl","colab_type":"code","outputId":"8a7ef806-db7a-4e36-9714-3db52e6cacf0","executionInfo":{"status":"ok","timestamp":1588362893688,"user_tz":240,"elapsed":76953,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":564}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import keras\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from art.classifiers import KerasClassifier\n","from art.utils import load_dataset\n","import random\n","from keras.models import Sequential\n","from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","tf.compat.v1.disable_eager_execution()\n","\n","from cleverhans.compat import softmax_cross_entropy_with_logits\n","from cleverhans.utils_keras import KerasModelWrapper\n","\n","\n","\n","# Step 1: Load the CIFAR-10 Dataset\n","(x_train_victim, y_train_victim), (x_test_victim, y_test_victim), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n","print(\"x_train_victim shape: \" + str(x_train_victim.shape) + \"\\n\" + \"x_train_victim size: \" + str(x_train_victim.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n","      \"y_train_victim shape: \" + str(y_train_victim.shape) + \"\\n\" + \"y_train_victim size: \" + str(y_train_victim.size) + \"\\n\" +\n","      \"x_test_victim shape: \" + str(x_test_victim.shape) + \"\\n\" + \"x_test_victim size: \" + str(x_test_victim.size) + \"\\n\" +\n","      \"y_test_victim shape: \" + str(y_test_victim.shape) + \"\\n\" + \"y_test_victim size: \" + str(y_test_victim.size) + \"\\n\")\n","print()\n","\n","\n","# Step 2: Load the victim model\n","classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n","IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n","victim_classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n","\n","\n","# Step 3: Evaluate the victim model on the benign dataset\n","predictions = victim_classifier.predict(x_test_victim) # giving the classifier the x_test of the CIFAR-10 dataset.\n","accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_victim, axis=1)) / len(y_test_victim) # calculates the accuracy of the predictions\n","print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/cleverhans/utils_tf.py:341: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","x_train_victim shape: (50000, 32, 32, 3)\n","x_train_victim size: 153600000\n","y_train_victim shape: (50000, 10)\n","y_train_victim size: 500000\n","x_test_victim shape: (10000, 32, 32, 3)\n","x_test_victim size: 30720000\n","y_test_victim shape: (10000, 10)\n","y_test_victim size: 100000\n","\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f8303596978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f8303596978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:art.classifiers.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: Entity <bound method KerasLayer.call of <tensorflow_hub.keras_layer.KerasLayer object at 0x7f8303596978>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on benign test examples for victim classifier: 94.52000000000001%\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pmkSM0g_GHyE","colab_type":"code","outputId":"eb0f1365-44ef-4afd-c8ca-5a7e20f4bf33","executionInfo":{"status":"ok","timestamp":1588363061657,"user_tz":240,"elapsed":241371,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Step 4: Collect subset\n","def exract_subset(data, labels):\n","    x_pre = []  \n","    y_pre = []  \n","    #count = 0\n","    for index in range(0, len(data)):  \n","        x_pre.append(data[index])  \n","        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n","        y_pre.append(y_predict)\n","        #if y_predict != np.argmax(labels[index]):\n","            #print(str(np.argmax(labels[index])) + \" : \" + str(y_predict))\n","            #count = count + 1\n","    #print(count)\n","    x = np.asarray(x_pre)  \n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n","    return x, y\n","\n","X_subset, Y_subset = exract_subset( x_test_victim, y_test_victim )\n","print(\"X_subset shape: \" + str(X_subset.shape) + \"\\n\" + \"X_subset size: \" + str(X_subset.size) + \"\\n\" +\n","      \"Y_subset shape: \" + str(Y_subset.shape) + \"\\n\" + \"Y_subset size: \" + str(Y_subset.size) + \"\\n\")\n","\n","np.save('/content/gdrive/My Drive/X_subset', X_subset) \n","np.save('/content/gdrive/My Drive/Y_subset', Y_subset) "],"execution_count":4,"outputs":[{"output_type":"stream","text":["X_subset shape: (10000, 32, 32, 3)\n","X_subset size: 30720000\n","Y_subset shape: (10000, 10)\n","Y_subset size: 100000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t1NU-2c6zJvj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-JIOGhCmrBac","colab_type":"text"},"source":["Up to this point the victim classifer has been evaluted on the test set of cifar10 = 94.5% accuracy, and the test set has been extracted with the labels given by the victim model's predtiction, i.e. 10000 examples"]},{"cell_type":"code","metadata":{"id":"6hdaJHUsLVrM","colab_type":"code","outputId":"4ecd1a7c-3846-454a-e7de-27dfff891529","executionInfo":{"status":"ok","timestamp":1588359943605,"user_tz":240,"elapsed":263304,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["# Step 1: Load the subset data\n","X = np.load('/content/gdrive/My Drive/X_subset.npy') \n","Y = np.load('/content/gdrive/My Drive/Y_subset.npy') \n","print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n","      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n","print()\n","\n","x_train_substitute = X[:7500]\n","y_train_substitute = Y[:7500]\n","print(\"x_train_substitute shape: \" + str(x_train_substitute.shape) + \"\\n\" + \"x_train_substitute size: \" + str(x_train_substitute.size) + \"\\n\" + \n","      \"y_train_substitute shape: \" + str(y_train_substitute.shape) + \"\\n\" + \"y_train_substitute size: \" + str(y_train_substitute.size) + \"\\n\")\n","print()\n","\n","x_test_substitute = X[7500:]\n","y_test_substitute = Y[7500:]\n","print(\"x_test_substitute shape: \" + str(x_test_substitute.shape) + \"\\n\" + \"x_test_substitute size: \" + str(x_test_substitute.size) + \"\\n\" + \n","      \"y_test_substitute shape: \" + str(y_test_substitute.shape) + \"\\n\" + \"y_test_substitute size: \" + str(y_test_substitute.size) + \"\\n\")\n","print()\n","\n","\n","# Step 2: Create the model\n","model_substitute = Sequential()\n","model_substitute.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train_substitute.shape[1:]))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Conv2D(32, (3, 3)))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n","model_substitute.add(Dropout(0.25))\n","\n","model_substitute.add(Conv2D(64, (3, 3), padding=\"same\"))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Conv2D(64, (3, 3)))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n","model_substitute.add(Dropout(0.25))\n","\n","model_substitute.add(Flatten())\n","model_substitute.add(Dense(512))\n","model_substitute.add(Activation(\"relu\"))\n","model_substitute.add(Dropout(0.5))\n","model_substitute.add(Dense(10))\n","model_substitute.add(Activation(\"softmax\"))\n","\n","model_substitute.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","\n","\n","# Step 3: Create the classifier\n","substitute_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))\n","#substitute_classifier.fit(x_train_substitute, y_train_substitute, nb_epochs=10, batch_size=128)\n","\n","\n","\n","#Step 4: Evaluate the ART classifier on benign test examples\n","#predictions = substitute_classifier.predict(x_test_substitute)\n","#accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n","#print(\"Accuracy on benign test examples for substitute classifier: {}%\".format(accuracy * 100))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["X shape: (10000, 32, 32, 3)\n","X size: 30720000\n","Y shape: (10000, 10)\n","Y size: 100000\n","\n","\n","x_train_substitute shape: (7500, 32, 32, 3)\n","x_train_substitute size: 23040000\n","y_train_substitute shape: (7500, 10)\n","y_train_substitute size: 75000\n","\n","\n","x_test_substitute shape: (2500, 32, 32, 3)\n","x_test_substitute size: 7680000\n","y_test_substitute shape: (2500, 10)\n","y_test_substitute size: 25000\n","\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"-3JDApld2YoQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKGkIK_V2Ywh","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkNLPh19LVyV","colab_type":"code","outputId":"e79c4ca3-0488-4fd7-b263-560717c94b30","executionInfo":{"status":"error","timestamp":1588194843948,"user_tz":240,"elapsed":981255,"user":{"displayName":"AbdulHaseeb Ahmed","photoUrl":"","userId":"07734737363620020800"}},"colab":{"base_uri":"https://localhost:8080/","height":935}},"source":["def one_hot(value):\n","  vec = np.zeros((10))\n","  vec[value] = 1\n","  return vec\n","\n","def jacobian(predictions, inputs, num_classes):\n","    #That is, how does the kth element of yhat vary wrt x?\n","    return [tf.gradients(predictions[:, c], inputs)[0] for c in range(0, num_classes)]\n","\n","def jacobian_prediction_dimension(grads, predictions):\n","    return [grads[predictions[i]][i] for i in np.arange(len(predictions))]\n","\n","wrapper = KerasModelWrapper( model_substitute ) # create keras wrapper for substitute model\n","adv_train_epochs = 1 # run the loop for 2 runs genreating 22500 samples from 7500 samples\n","adv_train_set = x_train_substitute / 255.0 # assign the varaible adv_train_set the x_train which holds 7500 samples\n","\n","\n","for adv_train_epoch in range(adv_train_epochs): # loop for syntehtic data generation\n","    print(\"RUN: \" + str(adv_train_epoch))\n","    print(\"Before: \")\n","    print(adv_train_set.shape) # initial size of the x_train (7500, 32, 32, 3)\n","\n","    # Get labels from victim model and train substitute model\n","    oracle_labels = victim_classifier.predict(adv_train_set) # have the victim model label the x_train values, i.e. getting the y_train labels = 7500 labels\n","    print(\"Oracle Predict: \")\n","    print(oracle_labels.shape) # shape of the y_train = (7500, 10)\n","    substitute_classifier.fit(adv_train_set, oracle_labels, nb_epochs=10, batch_size=128) # fit the substitute model with the training set created thus far.    \n","\n","    # Convert the labels from victim model to one hot encoded vectors\n","    oracle_labels = np.zeros((adv_train_set.shape[0],10))\n","    for i in range(0,x_train_substitute.shape[0]):\n","        oracle_labels[i] = one_hot(np.argmax(victim_classifier.predict( adv_train_set[i].reshape( (1, adv_train_set[i].shape[ 0 ], adv_train_set[i].shape[ 1 ], adv_train_set[i].shape[ 2 ]) ) )))\n","    print(\"Inside Augment: \" + str(oracle_labels.shape))\n","    \n","    # Create a session\n","    with tf.Session() as sess:\n","        xm = model_substitute.layers[0].input \n","        yhat = wrapper.get_logits( xm )\n","        init = tf.global_variables_initializer()\n","        sess = tf.Session( )   \n","        sess.run(init) # Initializes the variables\n","        grads = sess.run(jacobian(yhat, xm, 10), feed_dict={xm: adv_train_set}) # compute the grads with the jacobian function\n","        jpd = jacobian_prediction_dimension(grads, np.argmax(oracle_labels, 1))\n","\n","    perturbed_set = []\n","    jbda_lambda = 0.1\n","    tau = 1\n","    jbda_epoch_lambda = jbda_lambda * np.power(-1, np.floor(adv_train_epoch/tau))\n","    for idx, example in enumerate(adv_train_set):\n","        new_example = example + jbda_epoch_lambda * (np.sign(jpd[idx]))\n","        perturbed_set.append(new_example)\n","    adv_train_set = np.vstack((adv_train_set, np.array(perturbed_set)))\n","\n","    print(\"After: \")\n","    print(adv_train_set.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["RUN: 0\n","Before: \n","(7500, 32, 32, 3)\n","Oracle Predict: \n","(7500, 10)\n","Epoch 1/10\n","58/58 [==============================] - 17s 293ms/step - loss: -5393184.5413 - accuracy: 0.8138\n","Epoch 2/10\n","58/58 [==============================] - 17s 287ms/step - loss: -3887221258.6207 - accuracy: 0.8223\n","Epoch 3/10\n","58/58 [==============================] - 17s 286ms/step - loss: -177766202368.0000 - accuracy: 0.8238\n","Epoch 4/10\n","58/58 [==============================] - 17s 288ms/step - loss: -2360795164248.2759 - accuracy: 0.8300\n","Epoch 5/10\n","58/58 [==============================] - 17s 290ms/step - loss: -15791122347820.1387 - accuracy: 0.8280\n","Epoch 6/10\n","58/58 [==============================] - 17s 287ms/step - loss: -69285691721939.8672 - accuracy: 0.8367\n","Epoch 7/10\n","58/58 [==============================] - 17s 290ms/step - loss: -229396982367337.9375 - accuracy: 0.8365\n","Epoch 8/10\n","58/58 [==============================] - 17s 291ms/step - loss: -624174160313238.1250 - accuracy: 0.8339\n","Epoch 9/10\n","58/58 [==============================] - 17s 290ms/step - loss: -1466697582767704.5000 - accuracy: 0.8318\n","Epoch 10/10\n","58/58 [==============================] - 17s 289ms/step - loss: -3086666773118411.0000 - accuracy: 0.8376\n","Inside Augment: (7500, 10)\n","After: \n","(15000, 32, 32, 3)\n","RUN: 1\n","Before: \n","(15000, 32, 32, 3)\n","Oracle Predict: \n","(15000, 10)\n","Epoch 1/10\n","117/117 [==============================] - 35s 298ms/step - loss: -8425886794995030.0000 - accuracy: 0.7594\n","Epoch 2/10\n","117/117 [==============================] - 39s 338ms/step - loss: -28081313775994656.0000 - accuracy: 0.6983\n","Epoch 3/10\n","117/117 [==============================] - 34s 292ms/step - loss: -78437668584542176.0000 - accuracy: 0.6964\n","Epoch 4/10\n","117/117 [==============================] - 34s 293ms/step - loss: -187218982596742720.0000 - accuracy: 0.7033\n","Epoch 5/10\n","117/117 [==============================] - 35s 297ms/step - loss: -395072054410050752.0000 - accuracy: 0.7073\n","Epoch 6/10\n","117/117 [==============================] - 35s 296ms/step - loss: -754292495574366080.0000 - accuracy: 0.7204\n","Epoch 7/10\n","117/117 [==============================] - 35s 295ms/step - loss: -1337420811493311488.0000 - accuracy: 0.7287\n","Epoch 8/10\n","117/117 [==============================] - 35s 296ms/step - loss: -2224568062363631104.0000 - accuracy: 0.7121\n","Epoch 9/10\n","117/117 [==============================] - 35s 297ms/step - loss: -3522264160127178240.0000 - accuracy: 0.7132\n","Epoch 10/10\n","117/117 [==============================] - 35s 295ms/step - loss: -5349360957500814336.0000 - accuracy: 0.7214\n","Inside Augment: (15000, 10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"COWjZnOofiP8","colab_type":"code","colab":{}},"source":["print(adv_train_set.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WsCZtvT52ZVG","colab_type":"code","colab":{}},"source":["# Step 4: Collect subset\n","def exract_subset(data):\n","    x_pre = []  \n","    y_pre = []  \n","    #count = 0\n","    for index in range(0, len(data)):  \n","        x_pre.append(data[index])  \n","        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n","        y_pre.append(y_predict)\n","        #if y_predict != np.argmax(labels[index]):\n","            #print(str(np.argmax(labels[index])) + \" : \" + str(y_predict))\n","            #count = count + 1\n","    #print(count)\n","    x = np.asarray(x_pre)  \n","    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n","    return x, y\n","\n","X_synthetic, Y_synthetic = exract_subset( adv_train_set )\n","print(\"X_synthetic shape: \" + str(X_synthetic.shape) + \"\\n\" + \"X_synthetic size: \" + str(X_synthetic.size) + \"\\n\" +\n","      \"Y_synthetic shape: \" + str(Y_synthetic.shape) + \"\\n\" + \"Y_synthetic size: \" + str(Y_synthetic.size) + \"\\n\")\n","\n","np.save('/content/gdrive/My Drive/X_synthetic', X_synthetic) \n","np.save('/content/gdrive/My Drive/Y_synthetic', Y_synthetic) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zfyT_wUmfq4K","colab_type":"code","colab":{}},"source":["X_train = np.load('/content/gdrive/My Drive/X_synthetic.npy') \n","Y_train = np.load('/content/gdrive/My Drive/Y_synthetic.npy') \n","print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n","      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n","print()\n","\n","substitute_classifier.fit(X_train, Y_train, nb_epochs=10, batch_size=128)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zHHU1w5i2ZZ7","colab_type":"code","colab":{}},"source":["#Step 4: Evaluate the ART classifier on benign test examples\n","predictions = substitute_classifier.predict(x_test_substitute)\n","accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n","print(\"Accuracy on benign test examples for substitute classifier: {}%\".format(accuracy * 100))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3GXsltyL2aA_","colab_type":"code","colab":{}},"source":["substitute_classifier.save(\"/content/gdrive/My Drive/Attack_Transfer_Substitute_Classifier_V3.h5\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gv0poHGh2aHf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}